import streamlit as st
import os
import datetime
import json
import base64
import tempfile
import threading
import html
from io import BytesIO
from PIL import Image
from utils.ui_components import render_voice_command_ui, render_floating_voice_button
from utils.themes import apply_theme, THEMES
# Emoji picker removed to fix chat functionality
from utils.models import (
    get_gemini_response,
    get_vertex_ai_response,
    get_openai_response,
    get_anthropic_response,
    get_perplexity_response
)
# Use Google OAuth for secure authentication
from utils.google_auth import check_login, logout_user, get_current_user, is_admin
from utils.database import init_db, save_conversation, load_conversations, get_most_recent_chat
# Enhanced audio recording with WebRTC
from utils.webrtc_audio import audio_recorder_ui
# Text-to-speech with ElevenLabs
from utils.tts import render_tts_controls, render_play_button, text_to_speech

# Add CSS for toggle buttons
def add_toggle_button_css():
    st.markdown("""
    <style>
    .toggle-button {
        position: relative;
        width: 40px;
        height: 20px;
        background-color: #333;
        border-radius: 10px;
        cursor: pointer;
    }
    
    .toggle-button:before {
        content: '';
        position: absolute;
        width: 18px;
        height: 18px;
        border-radius: 50%;
        top: 1px;
        left: 1px;
        background-color: #555;
        transition: 0.2s;
    }
    
    .toggle-button.active {
        background-color: #4285f4;
    }
    
    .toggle-button.active:before {
        transform: translateX(20px);
        background-color: white;
    }
    
    /* Make buttons look like actual buttons */
    button {
        cursor: pointer;
    }
    </style>
    """, unsafe_allow_html=True)

# Set page configuration
st.set_page_config(
    page_title="AI Chat Studio",
    page_icon="assets/favicon.svg",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Initialize session state variables
if "messages" not in st.session_state:
    st.session_state.messages = []
if "user" not in st.session_state:
    st.session_state.user = None
if "current_model" not in st.session_state:
    st.session_state.current_model = "Gemini"
if "voice_commands_enabled" not in st.session_state:
    st.session_state.voice_commands_enabled = False
if "voice_commands_active" not in st.session_state:
    st.session_state.voice_commands_active = False
if "temperature" not in st.session_state:
    st.session_state.temperature = 0.7
if "uploaded_image" not in st.session_state:
    st.session_state.uploaded_image = None
    
# Voice command state variables
if "voice_commands_active" not in st.session_state:
    st.session_state.voice_commands_active = False
if "voice_processor" not in st.session_state:
    st.session_state.voice_processor = None
if "is_listening" not in st.session_state:
    st.session_state.is_listening = False
    
# Theme state - initialize before use
if "current_theme" not in st.session_state:
    st.session_state.current_theme = "Amazon Q Purple"
    
# Message cooldown to prevent double-sending
if "message_cooldown" not in st.session_state:
    st.session_state.message_cooldown = False

# Apply the current theme's CSS
theme_css = apply_theme(st.session_state.current_theme)
st.markdown(theme_css, unsafe_allow_html=True)

# Check user login
check_login()

# Helper function to encode image for API calls
def encode_image(uploaded_file):
    if uploaded_file is not None:
        # Read the file and encode it
        bytes_data = uploaded_file.getvalue()
        
        # Convert to base64
        encoded = base64.b64encode(bytes_data).decode('utf-8')
        return encoded
    return None

# Main function
def main():
    # Initialize database
    init_db()
    
    # Add CSS for toggle buttons and UI elements
    add_toggle_button_css()
    
    # Apply custom styling to match Google Gemini UI exactly
    st.markdown("""
    <style>
    /* Dark background for the app */
    .stApp {
        background-color: #0e1117;
    }
    
    /* Left sidebar styling */
    [data-testid="stSidebar"] {
        background-color: #0e1117;
        border-right: 1px solid #333;
    }
    
    /* Hide default Streamlit hamburger menu */
    section[data-testid="stSidebarUserContent"] {
        padding-top: 0rem;
    }
    
    /* Make the main content full width */
    .main .block-container {
        max-width: 100%;
        padding-top: 1rem;
        padding-left: 1rem;
        padding-right: 1rem;
    }
    
    /* Right sidebar styling */
    .right-sidebar {
        position: fixed;
        right: 0;
        top: 0;
        width: 250px;
        height: 100vh;
        padding: 1rem;
        background-color: #0e1117;
        border-left: 1px solid #333;
        overflow-y: auto;
        z-index: 10;
    }
    
    /* Main content area with space for the right sidebar */
    .main-content {
        margin-right: 250px;
    }
    
    /* Toggle button styling */
    .toggle-container {
        margin-top: 5px;
    }
    .toggle-button {
        background-color: #333;
        border-radius: 15px;
        display: inline-block;
        height: 20px;
        position: relative;
        width: 40px;
    }
    .toggle-button.active {
        background-color: #4285f4;
    }
    .toggle-button::after {
        background-color: white;
        border-radius: 50%;
        content: '';
        height: 16px;
        left: 2px;
        position: absolute;
        top: 2px;
        transition: all 0.3s;
        width: 16px;
    }
    .toggle-button.active::after {
        left: 22px;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # Left sidebar matching the Google Gemini interface
    with st.sidebar:
        # App section heading with icon
        st.markdown("""
        <div style="padding: 10px 0; cursor: pointer; display: flex; align-items: center;">
            <div style="background-color: #4285f4; border-radius: 50%; height: 28px; width: 28px; display: flex; align-items: center; justify-content: center; margin-right: 10px;">
                <span style="color: white; font-size: 16px;">G</span>
            </div>
            <span style="color: white; font-weight: 500; font-size: 16px;">AI Chat Studio</span>
        </div>
        """, unsafe_allow_html=True)
        
        # Chat Library section
        st.markdown("""
        <div style="margin-top: 20px; margin-bottom: 10px;">
            <span style="color: #888; font-size: 14px; font-weight: 500;">CHAT LIBRARY</span>
        </div>
        """, unsafe_allow_html=True)
        
        # Search input
        search_text = st.text_input("Search chats", key="search_chats", placeholder="Search for past prompts")
        
        # Display message if no chats are found
        st.markdown("""
        <div style="color: #888; font-size: 12px; padding: 5px 0;">
            No previous conversations found
        </div>
        """, unsafe_allow_html=True)
        
        # Horizontal separator
        st.markdown("<hr style='margin: 20px 0; border-color: #333;'>", unsafe_allow_html=True)
        
        # Capabilities section
        st.markdown("""
        <div style="margin-bottom: 10px;">
            <span style="color: #888; font-size: 14px; font-weight: 500;">CAPABILITIES</span>
        </div>
        """, unsafe_allow_html=True)
        
        # Capabilities list
        st.markdown("""
        <div style="padding: 5px 0;">
            <span style="color: white;">üìù Text & Code</span>
        </div>
        <div style="padding: 5px 0;">
            <span style="color: white;">üñºÔ∏è Images</span>
        </div>
        <div style="padding: 5px 0;">
            <span style="color: white;">üîä Audio</span>
        </div>
        """, unsafe_allow_html=True)
        
        # File upload area above logout button
        st.markdown("""
        <div style="margin-top: 30px; margin-bottom: 20px;">
            <div style="color: white; font-weight: 500; margin-bottom: 15px; font-size: 16px;">Upload files</div>
            <div style="border: 1px dashed #666; border-radius: 8px; padding: 20px; text-align: center; background-color: rgba(30, 30, 30, 0.6);">
                <div style="color: white; margin-bottom: 10px;">Drag and drop file here</div>
                <div style="color: #999; font-size: 12px; margin-bottom: 5px;">Limit 200MB per file ‚Ä¢</div>
                <div style="color: #999; font-size: 12px;">JPG, JPEG, PNG</div>
            </div>
        </div>
        """, unsafe_allow_html=True)
        
        # Browse files button
        browse_col1, browse_col2 = st.columns([3, 1])
        with browse_col1:
            browse_files = st.file_uploader("Browse files", type=["jpg", "jpeg", "png"], label_visibility="collapsed", key="sidebar_file_uploader")
            if browse_files:
                # Preview the uploaded files
                st.image(browse_files, width=150)
                st.session_state.uploaded_image = encode_image(browse_files)
                
        with browse_col2:
            st.markdown("""
            <div style="height: 38px;"></div>
            """, unsafe_allow_html=True)
        
        # Recent files section
        st.markdown("""
        <div style="margin-top: 20px; margin-bottom: 20px;">
            <div style="color: white; font-weight: 500; margin-bottom: 10px; font-size: 16px;">Recent files</div>
            <div style="color: #999; font-size: 14px; text-align: center; padding: 15px 0;">No recent files found</div>
        </div>
        """, unsafe_allow_html=True)
        
        # Logout button at bottom
        st.markdown("<div style='margin-top: 30px;'></div>", unsafe_allow_html=True)
        if st.button("Logout", use_container_width=True, type="primary", key="logout_bottom"):
            logout_user()
            st.rerun()
    
    # Right sidebar for tools panel exactly as in Google Gemini
    right_col = st.container()
    
    # Create a column layout - left sidebar, main content and right sidebar
    # Create a 3-column layout with more space for the left sidebar
    left_sidebar, main_content, right_sidebar = st.columns([1.2, 5.8, 2])
    
    # Left sidebar with content
    with left_sidebar:
        # Display active model with badge
        st.markdown("""
        <div style="background-color: rgba(30, 30, 30, 0.6); border-radius: 8px; padding: 12px; margin-bottom: 20px; border: 1px solid #333;">
            <div style="display: flex; align-items: center;">
                <div style="background-color: #4285f4; border-radius: 50%; height: 24px; width: 24px; display: flex; align-items: center; justify-content: center; margin-right: 10px;">
                    <span style="color: white; font-size: 14px;">G</span>
                </div>
                <div>
                    <div style="color: white; font-weight: 500; font-size: 14px;">Gemini 2.0 Pro</div>
                    <div style="color: #888; font-size: 12px;">Premium model</div>
                </div>
            </div>
        </div>
        """, unsafe_allow_html=True)
    
    # Main content area with chat UI
    with main_content:
        # Main chat area with exactly the header shown in the screenshot
        st.markdown("""
        <div style="text-align: center; padding: 20px 0;">
            <h1 style="font-size: 2.2rem; margin-bottom: 5px; color: white;">Talk with AI live</h1>
            <p style="color: #888; font-size: 1.1rem;">Interact with AI models using text, code, images, audio, or upload files</p>
        </div>
        """, unsafe_allow_html=True)
        
        # Persona selector dropdown across the width
        st.markdown("""
        <div style="margin-bottom: 20px;">
            <div style="background-color: rgba(30, 30, 30, 0.6); border: 1px solid #333; border-radius: 8px; padding: 10px; margin-bottom: 15px;">
                <p style="color: white; margin-bottom: 5px; font-weight: 500;">Select Persona</p>
            </div>
        </div>
        """, unsafe_allow_html=True)
        
        # Create a dropdown for persona selection
        personas = [
            "Default Assistant", 
            "Creative Writer", 
            "Data Scientist", 
            "Code Expert", 
            "Language Tutor",
            "Math Tutor"
        ]
        
        selected_persona = st.selectbox(
            "Choose a persona for the AI",
            personas,
            index=0,
            key="persona_selector",
            label_visibility="collapsed"
        )
        
        # Model display box exactly as shown in the screenshot
        st.markdown("""
        <div style="max-width: 600px; margin: 15px auto; padding: 10px; background-color: rgba(20, 20, 20, 0.6); border-radius: 8px; border: 1px solid #333;">
            <p style="margin: 0; color: #4285f4; text-align: center;">
                <span style="color: #4285f4; font-weight: normal;">Model:</span> <span style="color: #4285f4;">Gemini 2.0 Pro (gemini-1.5-pro)</span>
            </p>
        </div>
        """, unsafe_allow_html=True)
        
        # Add custom CSS for improved message container
        st.markdown("""
        <style>
        .chat-container {
            height: 600px !important;
            overflow-y: auto;
            padding-right: 15px;
            margin-bottom: 20px;
            border-radius: 10px;
            background-color: rgba(40, 40, 40, 0.2);
        }
        .stChatInputContainer {
            min-height: 80px !important;
            padding: 10px !important;
            margin-top: 15px !important;
        }
        .stChatInput {
            min-height: 60px !important;
            font-size: 16px !important;
        }
        </style>
        """, unsafe_allow_html=True)
        
        # Create a taller fixed-height container for chat messages with Google AI Studio style
        chat_container = st.container(height=600, border=False)
        st.markdown('<div class="chat-container">', unsafe_allow_html=True)
        
        # Display chat messages in a clean Google AI Studio style within the fixed container
        with chat_container:
            for i, message in enumerate(st.session_state.messages):
                # Custom styling for messages based on role
                if message["role"] == "user":
                    # User message with custom styling
                    st.markdown(f"""
                    <div style="display: flex; align-items: start; margin-bottom: 10px;">
                        <div style="background-color: #f50057; color: white; border-radius: 50%; height: 32px; width: 32px; display: flex; align-items: center; justify-content: center; margin-right: 10px; flex-shrink: 0;">
                            <span>üë§</span>
                        </div>
                        <div style="background-color: #1e1e1e; border-radius: 10px; padding: 10px; max-width: 90%;">
                            <p style="margin: 0; color: white; white-space: pre-wrap;">{html.escape(message["content"]).replace(chr(10), '<br>')}</p>
                        </div>
                    </div>
                    """, unsafe_allow_html=True)
                
                # If there's an image in the message
                if message.get("image"):
                    try:
                        # Display the image below the text
                        image_data = base64.b64decode(message["image"])
                        image = Image.open(BytesIO(image_data))
                        st.image(image, caption="Uploaded Image", width=300)
                    except Exception as e:
                        st.error(f"Could not display image: {str(e)}")
                else:
                    # AI message with custom styling
                    st.markdown(f"""
                    <div style="display: flex; align-items: start; margin-bottom: 10px;">
                        <div style="background-color: #8c52ff; color: white; border-radius: 50%; height: 32px; width: 32px; display: flex; align-items: center; justify-content: center; margin-right: 10px; flex-shrink: 0;">
                            <span>ü§ñ</span>
                        </div>
                        <div style="background-color: #272727; border-radius: 10px; padding: 10px; max-width: 90%;">
                            <p style="margin: 0; color: white; white-space: pre-wrap;">{html.escape(message["content"]).replace(chr(10), '<br>')}</p>
                        </div>
                    </div>
                    """, unsafe_allow_html=True)
                    
                    # Add text-to-speech and reaction buttons for AI messages
                    if i > 0 and message["role"] == "assistant":
                        # Create a unique key for each message's reaction section
                        message_key = f"reaction_{i}"
                        
                        # Initialize reaction counts in session state if not already set
                        if message_key not in st.session_state:
                            st.session_state[message_key] = {"üëç": 0, "‚ù§Ô∏è": 0, "üòÇ": 0, "üòÆ": 0, "üî•": 0}
                        
                        # Display the reactions as small text instead of buttons
                        reaction_html = ""
                        reactions = ["üëç", "‚ù§Ô∏è", "üòÇ", "üòÆ", "üî•"]
                        
                        for emoji in reactions:
                            count = st.session_state[message_key][emoji]
                            reaction_html += f"<span style='margin-right:8px;font-size:15px;'>{emoji} {count if count > 0 else ''}</span>"
                        
                        # Show them in a clean HTML layout
                        st.markdown(f"""
                        <div style="margin-top:5px;margin-bottom:10px;margin-left:40px;">
                            {reaction_html}
                        </div>
                        """, unsafe_allow_html=True)
                        
                        # Add buttons row: Play (TTS), Copy, and React
                        tts_col, react_col, copy_col = st.columns([1, 1, 2])
                        
                        # Text-to-speech button
                        with tts_col:
                            # Use the render_play_button from utils/tts.py
                            render_play_button(message["content"], key=f"tts_{i}")
                        
                        # React button
                        if react_col.button("üëç React", key=f"react_btn_{i}", use_container_width=True):
                            st.session_state[message_key]["üëç"] += 1
                            
                        # Copy text button
                        if copy_col.button("üìã Copy Text", key=f"copy_btn_{i}", use_container_width=True):
                            # Use JavaScript to copy to clipboard via streamlit component
                            st.markdown(f"""
                            <script>
                                var textToCopy = {json.dumps(message["content"])};
                                navigator.clipboard.writeText(textToCopy);
                            </script>
                            """, unsafe_allow_html=True)
                            st.toast("Text copied to clipboard!")
                            
        
        # Close the chat container div
        st.markdown('</div>', unsafe_allow_html=True)
        
        # Add chat input with ghosted icons inside
        chat_input_container = st.container()
        with chat_input_container:
            st.markdown("""
            <style>
            /* Style for the chat input container with icons */
            .chat-input-with-icons {
                position: relative;
                width: 100%;
                margin-top: 20px;
            }
            
            /* Icon container at the right side of the input */
            .chat-icons {
                position: absolute;
                right: 15px;
                top: 50%;
                transform: translateY(-50%);
                display: flex;
                gap: 12px;
                z-index: 100;
            }
            
            /* Individual icon styling */
            .chat-icon {
                opacity: 0.6;
                cursor: pointer;
                transition: opacity 0.2s;
                width: 20px;
                height: 20px;
            }
            
            .chat-icon:hover {
                opacity: 1;
            }
            </style>
            
            <div class="chat-input-with-icons">
                <div class="chat-icons">
                    <svg class="chat-icon" xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="#888">
                        <path d="M19 13h-6v6h-2v-6H5v-2h6V5h2v6h6z"/>
                    </svg>
                    <svg class="chat-icon" xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="#888">
                        <path d="M9 16h6v-6h4l-7-7-7 7h4zm-4 2h14v2H5z"/>
                    </svg>
                    <svg class="chat-icon" xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="#888">
                        <path d="M12 14c1.66 0 2.99-1.34 2.99-3L15 5c0-1.66-1.34-3-3-3S9 3.34 9 5v6c0 1.66 1.34 3 3 3zm5.3-3c0 3-2.54 5.1-5.3 5.1S6.7 14 6.7 11H5c0 3.41 2.72 6.23 6 6.72V21h2v-3.28c3.28-.48 6-3.3 6-6.72h-1.7z"/>
                    </svg>
                    <svg class="chat-icon" xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="#888">
                        <path d="M9.4 10.5l4.77-8.26C13.47 2.09 12.75 2 12 2c-2.4 0-4.6.85-6.32 2.25l3.66 6.35.06-.1zM21.54 9c-.92-2.92-3.15-5.26-6-6.34L11.88 9h9.66zm.26 1h-7.49l.29.5 4.76 8.25C21 16.97 22 14.61 22 12c0-.69-.07-1.35-.2-2z"/>
                    </svg>
                </div>
            </div>
            """, unsafe_allow_html=True)
            
            # Add the actual chat input (will appear with icons overlaid)
            if user_input := st.chat_input("Message the AI...", key="chat_input_main"):
                # Check if we're in a cooldown period (prevents double messages)
                if st.session_state.message_cooldown:
                    st.info("Message already sent! Please wait a moment...")
                    return
                    
                # Set cooldown to prevent double sending
                st.session_state.message_cooldown = True
                    
                # If document was uploaded and button clicked, use document text as message
                if hasattr(st.session_state, 'document_text'):
                    user_input = st.session_state.document_text
                    # Clear it after use
                    delattr(st.session_state, 'document_text')
                
                # Create message object
                user_message = {"role": "user", "content": user_input}
                
                # Add image to message if one is uploaded
                if st.session_state.uploaded_image:
                    user_message["image"] = st.session_state.uploaded_image
                    
                # Add audio to message if recorded
                if hasattr(st.session_state, 'audio_data') and st.session_state.audio_data:
                    user_message["audio"] = st.session_state.audio_data
                    # Clear audio data after use
                    st.session_state.audio_data = None
                    st.session_state.audio_path = None
                
                # Add user message to chat
                st.session_state.messages.append(user_message)
                
                # Get AI response based on selected model
                with st.spinner(f"Thinking... using {st.session_state.current_model}"):
                    try:
                        image_data = user_message.get("image")
                        model_name = st.session_state.current_model.lower()
                        
                        # Extract model call sign from selected model if available
                        model_call_sign = None
                        if "(" in st.session_state.current_model and ")" in st.session_state.current_model:
                            model_call_sign = st.session_state.current_model.split("(")[1].split(")")[0]
                        
                        # Gemini models
                        if "gemini" in model_name:
                            # Use extracted call sign or fallback to default
                            gemini_version = model_call_sign if model_call_sign else "gemini-1.5-pro"
                            
                            # Get audio data if available
                            audio_data = user_message.get("audio")
                            
                            ai_response = get_gemini_response(
                                user_input, 
                                st.session_state.messages,
                                image_data=image_data,
                                audio_data=audio_data,
                                temperature=st.session_state.temperature,
                                model_name=gemini_version
                            )
                        
                        # Vertex AI models - direct routing to appropriate API based on model
                        elif "vertex ai" in model_name:
                            if "claude" in model_name.lower():
                                # Use the extracted call sign or default to Claude 3.5
                                claude_model = model_call_sign if model_call_sign else "claude-3-5-sonnet-20241022"
                                ai_response = get_vertex_ai_response(
                                    user_input, 
                                    st.session_state.messages,
                                    model_name=claude_model,
                                    image_data=image_data,
                                    temperature=st.session_state.temperature
                                )
                            else:
                                # Default Vertex AI model
                                ai_response = get_vertex_ai_response(
                                    user_input, 
                                    st.session_state.messages,
                                    image_data=image_data,
                                    temperature=st.session_state.temperature
                                )
                        
                        # OpenAI models
                        elif "openai" in model_name or "gpt" in model_name:
                            # Use extracted call sign or fallback to default
                            gpt_version = model_call_sign if model_call_sign else "gpt-4o"
                            
                            ai_response = get_openai_response(
                                user_input, 
                                st.session_state.messages,
                                model_name=gpt_version,
                                image_data=image_data,
                                temperature=st.session_state.temperature
                            )
                        
                        # Anthropic models
                        elif "anthropic" in model_name or "claude" in model_name:
                            # Use extracted call sign or fallback to default
                            claude_version = model_call_sign if model_call_sign else "claude-3-5-sonnet-20241022"
                            
                            ai_response = get_anthropic_response(
                                user_input, 
                                st.session_state.messages,
                                model_name=claude_version,
                                image_data=image_data,
                                temperature=st.session_state.temperature
                            )
                        
                        # Perplexity models
                        elif "perplexity" in model_name:
                            # Use extracted call sign or fallback to default
                            pplx_version = model_call_sign if model_call_sign else "mistral-8x7b-instruct"
                            
                            ai_response = get_perplexity_response(
                                user_input, 
                                st.session_state.messages,
                                model_name=pplx_version,
                                temperature=st.session_state.temperature
                            )
                        
                        # Default to Gemini if model not recognized
                        else:
                            ai_response = get_gemini_response(
                                user_input, 
                                st.session_state.messages, 
                                image_data=image_data,
                                temperature=st.session_state.temperature
                            )
                        
                        # Add AI response to messages
                        st.session_state.messages.append({"role": "assistant", "content": ai_response})
                        
                        # Save the conversation to database for persistence
                        save_conversation(
                            username=get_current_user() or "anonymous", 
                            model=st.session_state.current_model,
                            messages=st.session_state.messages
                        )
                        
                        # Clear image after use
                        st.session_state.uploaded_image = None
                        
                    except Exception as e:
                        st.error(f"Error generating response: {str(e)}")
                        
                    # Reset cooldown to allow new messages
                    st.session_state.message_cooldown = False
                    
                # Rerun to update UI
                st.rerun()
    # Right sidebar panel exactly like Google Gemini UI
    with right_sidebar:
        # More compact sidebar with model, tokens, and temperature sections combined
        st.markdown("""
        <style>
        /* Make the right sidebar more compact */
        .compact-sidebar-section {
            margin-bottom: 10px;
            padding-bottom: 10px;
            border-bottom: 1px solid #333;
        }
        .compact-sidebar-title {
            display: flex;
            align-items: center;
            margin-bottom: 8px;
        }
        .compact-sidebar-icon {
            margin-right: 8px;
        }
        .compact-sidebar-content {
            background-color: #1e1e1e;
            border-radius: 8px;
            padding: 10px;
            margin-bottom: 10px;
        }
        </style>
        
        <div class="compact-sidebar-section">
            <div class="compact-sidebar-title">
                <svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" fill="#888" viewBox="0 0 24 24">
                    <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zm0 16H5V5h14v14z"/>
                    <path d="M7 10h10v2H7z"/>
                </svg>
                <span style="margin-left: 8px; color: white; font-weight: 500; font-size: 14px;">Model</span>
            </div>
            <div class="compact-sidebar-content">
                <div style="font-size: 14px; color: white; font-weight: 500;">Gemini 2.0 Pro</div>
                <div style="font-size: 12px; color: #888; margin-top: 3px;">Preview (03-26)</div>
            </div>
        </div>
        """, unsafe_allow_html=True)
        
        # 2 & 3. Token count and Temperature in compact format
        st.markdown("""
        <div class="compact-sidebar-section">
            <div class="compact-sidebar-title">
                <svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" fill="#888" viewBox="0 0 24 24">
                    <path d="M20 2H4c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h16c1.1 0 2-.9 2-2V4c0-1.1-.9-2-2-2zm-9 2h2v2h-2V4zM9 8h2v2H9V8zm-4 8h2v2H5v-2zm0-8h2v2H5V8zm0-4h2v2H5V4zm4 12h2v2H9v-2zm4 0h2v2h-2v-2zm0-4h2v2h-2v-2zm0-8h2v2h-2V4zm4 4h2v2h-2V8zm0 8h2v2h-2v-2zm0-4h2v2h-2v-2zm0-8h2v2h-2V4z"/>
                </svg>
                <span style="margin-left: 8px; color: white; font-weight: 500; font-size: 14px;">Token count</span>
            </div>
            <div style="color: #888; font-size: 14px; margin-bottom: 10px;">0 / 1048576</div>
        </div>

        <div class="compact-sidebar-section">
            <div class="compact-sidebar-title">
                <svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" fill="#888" viewBox="0 0 24 24">
                    <path d="M15 13V5c0-1.66-1.34-3-3-3S9 3.34 9 5v8c-1.21.91-2 2.37-2 4 0 2.76 2.24 5 5 5s5-2.24 5-5c0-1.63-.79-3.09-2-4zm-4-8c0-.55.45-1 1-1s1 .45 1 1h-2z"/>
                </svg>
                <span style="margin-left: 8px; color: white; font-weight: 500; font-size: 14px;">Temperature</span>
            </div>
        """, unsafe_allow_html=True)
        
        # Temperature slider that matches the design
        temperature = st.slider(
            label="Temperature",
            min_value=0.0, 
            max_value=1.0, 
            value=0.7, 
            step=0.01,
            label_visibility="collapsed",
            key="temperature_sidebar"
        )
        
        if temperature != st.session_state.temperature:
            st.session_state.temperature = temperature
        
        # 4. Tools section in a more compact format
        st.markdown("""
        <div class="compact-sidebar-section">
            <div class="compact-sidebar-title">
                <svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" fill="#888" viewBox="0 0 24 24">
                    <path d="M22.7 19l-9.1-9.1c.9-2.3.4-5-1.5-6.9-2-2-5-2.4-7.4-1.3L9 6 6 9 1.6 4.7C.4 7.1.9 10.1 2.9 12.1c1.9 1.9 4.6 2.4 6.9 1.5l9.1 9.1c.4.4 1 .4 1.4 0l2.3-2.3c.5-.4.5-1.1.1-1.4z"/>
                </svg>
                <span style="margin-left: 8px; color: white; font-weight: 500; font-size: 14px;">Tools</span>
            </div>
        """, unsafe_allow_html=True)
        
        # Toggle switches for tools - using actual interactable components with compact styling
        # Initialize toggle states if not already set
        for tool in ["structured_output", "code_execution", "function_calling", "grounding"]:
            if f"tool_{tool}" not in st.session_state:
                st.session_state[f"tool_{tool}"] = False
        
        # Create compact tools layout with columns
        st.markdown("""
        <style>
        .tool-toggle {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 5px;
            padding: 2px 0;
        }
        .tool-toggle span {
            color: white;
            font-size: 13px;
        }
        </style>
        """, unsafe_allow_html=True)
        
        # Create a 2-column layout for toggles to save vertical space
        col1, col2 = st.columns(2)
        
        # Left column toggles
        with col1:
            # Structured output toggle
            st.markdown("""<div class="tool-toggle">
                <span>Structured output</span>
            </div>""", unsafe_allow_html=True)
            structured_output = st.checkbox("", value=st.session_state.tool_structured_output, key="structured_output_toggle", label_visibility="collapsed")
            if structured_output != st.session_state.tool_structured_output:
                st.session_state.tool_structured_output = structured_output
            
            # Function calling toggle
            st.markdown("""<div class="tool-toggle">
                <span>Function calling</span>
            </div>""", unsafe_allow_html=True)
            function_calling = st.checkbox("", value=st.session_state.tool_function_calling, key="function_calling_toggle", label_visibility="collapsed")
            if function_calling != st.session_state.tool_function_calling:
                st.session_state.tool_function_calling = function_calling
        
        # Right column toggles
        with col2:
            # Code execution toggle
            st.markdown("""<div class="tool-toggle">
                <span>Code execution</span>
            </div>""", unsafe_allow_html=True)
            code_execution = st.checkbox("", value=st.session_state.tool_code_execution, key="code_execution_toggle", label_visibility="collapsed")
            if code_execution != st.session_state.tool_code_execution:
                st.session_state.tool_code_execution = code_execution
            
            # Grounding toggle
            st.markdown("""<div class="tool-toggle">
                <span>Grounding</span>
            </div>""", unsafe_allow_html=True)
            grounding = st.checkbox("", value=st.session_state.tool_grounding, key="grounding_toggle", label_visibility="collapsed")
            if grounding != st.session_state.tool_grounding:
                st.session_state.tool_grounding = grounding
        
        # Close the section
        st.markdown("""</div>""", unsafe_allow_html=True)
        
        # Actions section with real buttons
        st.markdown("""<div style="margin-top: 30px;"></div>""", unsafe_allow_html=True)
        
        # Extension tools section title
        st.markdown("""
        <div style="display: flex; align-items: center; margin-bottom: 15px; margin-top: 30px;">
            <svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" fill="#888" viewBox="0 0 24 24">
                <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zm0 16H5V5h14v14z"/>
                <path d="M7 12h4v-2H7V7h6v2h-4v2h4v2h-4v2h6v-2h-2z"/>
            </svg>
            <span style="margin-left: 10px; color: white; font-weight: 500;">Extensions</span>
        </div>
        """, unsafe_allow_html=True)
        
        # Feature buttons section with minimal styling
        st.markdown("""
        <div style="margin-bottom: 20px; color: #888; font-size: 12px;">
            Use the icons in the chat input to:
            <ul style="margin-top: 5px; margin-left: 15px;">
                <li>Access files from Google Drive</li>
                <li>Upload documents & images</li>
                <li>Record audio for transcription</li>
                <li>Capture & analyze photos</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)
            
        # Hidden input tabs for different input types
        input_tabs = st.tabs(["Image Upload", "Audio Recording", "File Upload"])
        
        # Safety settings link
        st.markdown("""
        <div style="margin-top: 20px; text-align: right;">
            <a href="#" style="color: #888; font-size: 12px; text-decoration: none;">Safety settings</a>
        </div>
        """, unsafe_allow_html=True)
        
        # Image upload tab
        with input_tabs[0]:
            uploaded_file = st.file_uploader("Upload an image for analysis", type=["jpg", "jpeg", "png"])
            if uploaded_file:
                # Save the uploaded image to session state
                st.session_state.uploaded_image = encode_image(uploaded_file)
                
                # Preview the image
                st.image(uploaded_file, caption="Image ready for analysis", width=300)
        
        # Audio recording tab - Enhanced with WebRTC
        with input_tabs[1]:
            if "audio_data" not in st.session_state:
                st.session_state.audio_data = None
                st.session_state.audio_path = None
                st.session_state.audio_recording_unavailable = False
            
            st.markdown("### Enhanced Audio Recording")
            st.markdown("Record audio with adjustable duration using your microphone")
            
            # Try using WebRTC recorder first
            try:
                # Use the enhanced WebRTC audio recorder
                base64_audio = audio_recorder_ui(
                    key="webrtc_recorder",
                    title="Audio Recording",
                    description="Click start button to begin recording. Click stop when you're done.",
                    durations=[15, 30, 60, 120],
                    show_description=True,
                    show_playback=True
                )
                
                # If audio was recorded, store it in session state
                if base64_audio:
                    st.session_state.audio_data = base64_audio
                    # Path is already stored by the recorder in session state
                    st.session_state.audio_path = st.session_state.get("webrtc_recorder_file_path")
                    
                    # Show success message
                    st.success("Audio recorded successfully!")
                    st.info("You can now send a message to analyze this audio.")
                
            except Exception as e:
                # Fallback to legacy recording if WebRTC fails
                st.error(f"Enhanced audio recording unavailable: {str(e)}")
                st.info("Falling back to basic audio recording...")
                st.session_state.audio_recording_unavailable = True
                
                # Display legacy recording interface
                if not st.session_state.audio_recording_unavailable:
                    st.write("Choose recording duration:")
                    b1, b2 = st.columns(2)
                    
                    # Record 5-second audio
                    if b1.button("Record Audio (5 seconds)", use_container_width=True):
                        try:
                            from utils.audio import record_audio, encode_audio, cleanup_audio_file
                            audio_bytes, temp_file_path = record_audio(duration=5)
                            st.session_state.audio_data = encode_audio(audio_bytes)
                            st.session_state.audio_path = temp_file_path
                            st.success("Audio recorded successfully!")
                            st.audio(temp_file_path)
                        except Exception as e:
                            error_message = str(e)
                            if "microphone is not accessible" in error_message or "Invalid input device" in error_message:
                                st.error("Microphone not available in this environment.")
                                st.info("You can upload an audio file instead or use text input.")
                                st.session_state.audio_recording_unavailable = True
                            else:
                                st.error(f"Failed to record audio: {error_message}")
                    
                    # Record 10-second audio
                    if b2.button("Record Audio (10 seconds)", use_container_width=True):
                        try:
                            from utils.audio import record_audio, encode_audio, cleanup_audio_file
                            audio_bytes, temp_file_path = record_audio(duration=10)
                            st.session_state.audio_data = encode_audio(audio_bytes)
                            st.session_state.audio_path = temp_file_path
                            st.success("Audio recorded successfully!")
                            st.audio(temp_file_path)
                        except Exception as e:
                            error_message = str(e)
                            if "microphone is not accessible" in error_message or "Invalid input device" in error_message:
                                st.error("Microphone not available in this environment.")
                                st.info("You can upload an audio file instead or use text input.")
                                st.session_state.audio_recording_unavailable = True
                            else:
                                st.error(f"Failed to record audio: {error_message}")
                else:
                    # Show alternative options when recording is unavailable
                    st.warning("Audio recording is not available in this environment.")
                    st.info("You can upload a pre-recorded audio file or use text input instead.")
            
            # Separator
            st.markdown("---")
            
            # Upload audio file as alternative
            st.markdown("### Upload Audio File")
            st.markdown("Alternatively, upload a pre-recorded audio file")
            
            uploaded_audio = st.file_uploader("Upload audio file", type=["wav", "mp3", "ogg"], key="audio_upload")
            if uploaded_audio:
                try:
                    # Read the file and encode it
                    audio_bytes = uploaded_audio.getvalue()
                    
                    # Create temporary file
                    temp_file = tempfile.NamedTemporaryFile(suffix="." + uploaded_audio.name.split(".")[-1], delete=False)
                    temp_file_path = temp_file.name
                    temp_file.write(audio_bytes)
                    temp_file.close()
                    
                    # Save to session state
                    from utils.audio import encode_audio
                    st.session_state.audio_data = encode_audio(audio_bytes)
                    st.session_state.audio_path = temp_file_path
                    
                    # Show success and preview
                    st.success("Audio file uploaded successfully!")
                    st.audio(temp_file_path)
                except Exception as e:
                    st.error(f"Failed to process audio file: {str(e)}")
            
            # Button to clear recorded/uploaded audio
            if st.session_state.audio_data and st.button("Clear Audio"):
                if st.session_state.audio_path:
                    try:
                        from utils.audio import cleanup_audio_file
                        cleanup_audio_file(st.session_state.audio_path)
                    except:
                        pass
                st.session_state.audio_data = None
                st.session_state.audio_path = None
                st.rerun()
                
        # File upload tab
        with input_tabs[2]:
            uploaded_doc = st.file_uploader("Upload a document", type=["txt", "pdf", "doc", "docx"], 
                                          help="Upload a document for the AI to analyze")
            if uploaded_doc:
                # Read file content
                if uploaded_doc.type == "text/plain":
                    # Handle text files
                    text_content = uploaded_doc.getvalue().decode("utf-8")
                    st.text_area("Document Content", text_content, height=200)
                    if st.button("Send Document to AI"):
                        # Add document content to user message
                        st.session_state.document_text = f"I'm sharing this document with you: \n\n{text_content}\n\nPlease analyze this content."
                else:
                    # For other file types, just show the filename
                    st.info(f"File '{uploaded_doc.name}' uploaded. Send a message to the AI to analyze it.")
        
        # We already have a chat input in the main area with ghosted icons
    
    # This section is now merged into the sidebar, so we no longer use it
    if False: # Keeping the code for reference but never executing it
        # Right sidebar with enhanced Google AI Studio style settings
        with st.container():
            # Display user profile at the top of the sidebar if authenticated
            if st.session_state.is_authenticated and st.session_state.user:
                user_info = st.session_state.user
                user_name = user_info.get("name", "User")
                user_email = user_info.get("email", "")
                user_picture = user_info.get("picture", "")
                
                # User profile section with picture
                st.markdown(f"""
                <div style="padding: 15px 0; border-bottom: 1px solid #333; margin-bottom: 15px; display: flex; align-items: center;">
                    <div style="border-radius: 50%; overflow: hidden; width: 50px; height: 50px; margin-right: 10px;">
                        <img src="{user_picture}" style="width: 100%; height: 100%; object-fit: cover;" onerror="this.src='https://ui-avatars.com/api/?name={user_name}&background=random'">
                    </div>
                    <div>
                        <div style="font-weight: bold; color: white;">{user_name}</div>
                        <div style="font-size: 0.8rem; color: #aaa;">{user_email}</div>
                        <div style="font-size: 0.7rem; color: #4285f4; margin-top: 2px;">
                            {"Administrator" if is_admin() else "User"}
                        </div>
                    </div>
                </div>
                """, unsafe_allow_html=True)
                
                # Logout button
                if st.button("Logout", key="logout_button"):
                    logout_user()
                    st.rerun()
            
            st.markdown("""
            <div style="padding: 10px 0; border-bottom: 1px solid #333; margin-bottom: 15px;">
                <h3 style="color: #4285f4; font-size: 1.3rem;">AI Studio Settings</h3>
            </div>
            """, unsafe_allow_html=True)
            
            # Voice command functions
            def toggle_voice_commands(enable):
                """Toggle voice commands on/off"""
                if enable:
                    if not st.session_state.voice_processor:
                        try:
                            # Import voice command processor
                            from utils.voice_commands import VoiceCommandProcessor
                            
                            # Initialize processor with command callbacks
                            processor = VoiceCommandProcessor()
                            
                            # Register command callbacks
                            processor.register_callback("new_chat", lambda: st.session_state.update(messages=[]))
                            processor.register_callback("select_model_gemini", lambda: st.session_state.update(current_model="Gemini"))
                            processor.register_callback("select_model_claude", lambda: st.session_state.update(current_model="Anthropic (claude-3-5-sonnet-20241022)"))
                            processor.register_callback("select_model_gpt", lambda: st.session_state.update(current_model="OpenAI (gpt-4o)"))
                            processor.register_callback("increase_temperature", lambda: st.session_state.update(temperature=min(1.0, st.session_state.temperature + 0.1)))
                            processor.register_callback("decrease_temperature", lambda: st.session_state.update(temperature=max(0.0, st.session_state.temperature - 0.1)))
                            
                            # Add send message command
                            def send_dictated_message(text=None):
                                if text:
                                    # Create a new user message
                                    st.session_state.messages.append({"role": "user", "content": text})
                                    st.rerun()
                            
                            processor.register_callback("send_message", send_dictated_message)
                            
                            # Save the processor to session state
                            st.session_state.voice_processor = processor
                            
                            # Start listening
                            processor.start_listening()
                            st.session_state.is_listening = True
                        except Exception as e:
                            st.error(f"Failed to initialize voice commands: {str(e)}")
                            st.session_state.voice_commands_active = False
                            return
                    else:
                        # Restart the existing processor
                        st.session_state.voice_processor.start_listening()
                        st.session_state.is_listening = True
                else:
                    # Stop listening if processor exists
                    if st.session_state.voice_processor:
                        st.session_state.voice_processor.stop_listening()
                        st.session_state.is_listening = False
                
                # Update the active state
                st.session_state.voice_commands_active = enable
            
            # Theme selection
            st.markdown("""
            <div style="margin-top: 10px; border-top: 1px solid #333; padding-top: 15px;">
                <p style="font-weight: 500; margin-bottom: 5px;">Appearance</p>
            </div>
            """, unsafe_allow_html=True)
            
            selected_theme = st.selectbox(
                "Theme",
                options=list(THEMES.keys()),
                index=list(THEMES.keys()).index(st.session_state.current_theme),
                help="Select a color theme for the app"
            )
            
            # Apply theme if changed
            if selected_theme != st.session_state.current_theme:
                st.session_state.current_theme = selected_theme
                st.rerun()
            
            # Text-to-Speech settings section
            st.markdown("""
            <div style="margin-top: 10px; border-top: 1px solid #333; padding-top: 15px;">
                <p style="font-weight: 500; margin-bottom: 5px;">Speech</p>
            </div>
            """, unsafe_allow_html=True)
            
            # Initialize TTS settings in session state if not present
            if "tts_settings" not in st.session_state:
                st.session_state.tts_settings = {}
            
            # Add the TTS controls to the sidebar
            tts_settings = render_tts_controls()
            st.session_state.tts_settings = tts_settings
                
            # Model selection with specific model variants, icons, and call signs
            st.markdown("""
            <div style="margin-top: 10px; border-top: 1px solid #333; padding-top: 15px;">
                <p style="font-weight: 500; margin-bottom: 5px;">Model</p>
            </div>
            """, unsafe_allow_html=True)
            
            # Display model provider icons (without using nested columns)
            st.markdown("""
            <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 10px;">
                <div style="text-align: center;"><img src="data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyI+PHBhdGggZD0iTTIyLjA5IDE2LjEzTDIxLjEyIDE2LjIxTDIwLjU5IDE3LjA3QzE5Ljg0IDE4LjMzIDE4Ljc2IDE5LjMyIDE3LjQ3IDIwTDEyIDE2Ljg4TDYuNTMgMjBDNS4yNSAxOS4zNCA0LjE2IDE4LjM1IDMuNDEgMTcuMDlMMi44OCAxNi4yMkwxLjkxIDE2LjE0QzAuOTQgMTYuMDYgMCAxNS4zMiAwIDE0LjVDMCAxMy42OCAwLjk0IDEyLjkzIDEuOTEgMTIuODZMMi44OCAxMi43OEwzLjQxIDExLjkzQzQuMTYgMTAuNjcgNS4yNSA5LjY4IDYuNTMgOUwxMiAxMi4xMkwxNy40NyA5QzE4Ljc2IDkuNjggMTkuODQgMTAuNjcgMjAuNTkgMTEuOTNMMjEuMTIgMTIuNzhMMjIuMDkgMTIuODZDMjMuMDYgMTIuOTMgMjQgMTMuNjkgMjQgMTQuNUMyNCAxNS4zMiAyMy4wNiAxNi4wNiAyMi4wOSAxNi4xM00xMS45OSA1Ljg0TDcuNSAzLjA0QzYuNzggMi45NyA2LjA2IDMgNS4zNCAzLjA3TDQuNjEgMy4xNUwzLjkyIDMuNTRDMy4xNSAzLjk5IDIuNTMgNC42NyAyLjEyIDUuNUwyLjEgNS41QzEuODUgNi4wNiAxLjcyIDYuNjkgMS43MSA3LjM1TDEuNzYgOC4xOEwxLjk3IDguODRDMi4yMiA5LjUgMi41OSAxMC4wNiAzLjA5IDEwLjVMNy41IDcuNjlMMTIgNEwxNi41IDcuNjlMMjAuOTEgMTAuNUMyMS40MiAxMC4wNiAyMS43OCA5LjUgMjIuMDQgOC44NEwyMi4yNCA4LjE4TDIyLjI5IDcuMzVDMjIuMjcgNi42OCAyMi4xNSA2LjA2IDIxLjg5IDUuNUMyMS40OSA0LjY3IDIwLjg2IDMuOTkgMjAuMDkgMy41NEwxOS40IDMuMTVMMTguNjcgMy4wNkMxNy45NCAzIDE3LjIyIDIuOTcgMTYuNSAzLjA0TDExLjk5IDUuODQiIGZpbGw9IiM0Mjg1RjQiLz48L3N2Zz4=" width="24" alt="Gemini"><br><small>Gemini</small></div>
                <div style="text-align: center;"><img src="data:image/svg+xml;base64,<svg width="24" height="24" xmlns="http://www.w3.org/2000/svg"><path d="M22.56 17.44C21.15 15.45 18.18 12.83 18.18 12.83C19.06 11.24 20.08 8.7 20.11 7.04C20.15 5.27 19.46 4.12 18.32 3.46C17.05 2.73 15.64 3.05 14.79 3.48C13.94 3.91 13.07 4.62 12.73 6.15C12.5 7.15 12.65 8.08 12.78 8.74C12.86 9.12 13.02 9.57 13.18 10.01C13.42 10.69 13.89 11.69 13.41 12.61C13.14 13.13 12.88 13.38 12.59 13.47C12.42 13.52 12.4 13.49 12.29 13.44C12.26 13.43 12.22 13.41 12.15 13.38C12.06 13.34 11.95 13.28 11.84 13.18C11.62 13.01 11.3 12.71 11.11 12.23C10.75 11.28 10.7 10.16 10.95 9.14C11.03 8.77 11.19 8.38 11.35 7.99C11.47 7.68 11.69 7.43 11.83 7.11C12.81 5.11 12.42 1.75 9.78 0.79C8.68 0.37 7.58 0.49 6.57 1.02C5.66 1.5 4.9 2.34 4.5 3.62C4.2 4.54 4.18 5.45 4.35 6.37C4.53 7.39 4.86 8.37 5.2 9.2C5.37 9.61 5.65 10.27 5.71 10.53C5.73 10.64 5.76 10.72 5.54 11.02C5.32 11.32 5.18 11.32 5.06 11.28C4.75 11.19 4.36 10.83 4.14 10.59C3.79 10.2 3.44 9.67 3.26 9.24C3.12 8.89 3.03 8.52 2.96 8.14C2.8 7.37 2.84 6.6 3.09 5.82C3.53 4.47 4.83 3.54 6.02 3.15C7.56 2.63 9.41 2.89 10.73 3.85C12.42 5.06 13.41 7.4 13.39 9.73C13.39 10.19 13.33 10.42 13.33 10.73C13.33 10.94 13.52 11.12 13.65 11.17C13.8 11.23 13.94 11.17 14.06 11.06C14.25 10.89 14.4 10.61 14.51 10.34C15.2 8.42 14.99 6.01 13.7 4.63C11.96 2.76 8.91 2.85 7.33 4.8C6.85 5.4 6.57 6.12 6.45 6.93C6.32 7.8 6.44 8.65 6.61 9.27C6.72 9.65 6.95 10.21 7.04 10.59C7.06 10.69 7.08 10.77 7.08 10.82C7.09 10.92 7.12 10.98 7.1 11.03C7.02 11.18 6.89 11.24 6.76 11.29C6.57 11.38 6.39 11.33 6.23 11.27C6.1 11.22 5.98 11.15 5.88 11.09C5.65 10.96 5.41 10.74 5.21 10.47C4.94 10.11 4.69 9.64 4.57 9.1C4.07 7.36 4.31 5.24 5.8 3.87C7.44 2.36 10.15 2.41 11.75 3.96C12.8 5.01 13.28 6.47 13.25 7.96C13.22 9.88 12.29 11.85 11.6 12.98C10.82 14.26 9.76 15.37 8.72 16.41C7.94 17.18 6.74 18.23 6.18 18.83C5.64 19.39 5.29 19.94 5.14 20.37C5.03 20.67 5.04 20.95 5.07 21.15C5.19 22.05 5.74 22.33 6.2 22.48C6.82 22.68 7.55 22.64 8.14 22.47C9.06 22.21 9.88 21.68 10.57 21.14C11.71 20.26 12.58 19.1 13.67 18.06C16.06 15.78 18.88 13.63 21.23 11.29C21.6 10.92 22.08 10.44 22.48 10.04C22.67 9.85 22.94 9.56 23.09 9.41C23.19 9.29 23.38 9.08 23.48 8.75C23.65 8.17 23.51 7.68 23.41 7.47C23.29 7.19 23.13 7.05 22.89 6.95C22.53 6.81 22.19 6.83 21.98 6.86C21.69 6.91 21.4 7.01 21.14 7.1C20.89 7.19 20.64 7.31 20.4 7.45C20.09 7.63 19.79 7.87 19.49 8.11C19.23 8.3 18.97 8.55 18.76 8.75C18.57 8.94 18.34 9.2 18.18 9.36C17.94 9.61 17.81 9.74 17.64 9.91C17.05 10.5 16.46 11.09 15.89 11.69C15.88 11.69 15.87 11.7 15.86 11.71L13.91 13.81C13.5 14.26 13.12 14.74 12.76 15.21C12.61 15.42 12.35 15.8 12.19 15.99C12.02 16.19 11.88 16.41 11.75 16.65C11.53 17.06 11.5 17.4 11.65 17.74C11.82 18.13 12.21 18.35 12.58 18.43C13.21 18.57 13.84 18.42 14.51 18.25C14.93 18.15 15.29 17.97 15.59 17.8C15.8 17.68 16.02 17.53 16.18 17.41C16.61 17.1 17.01 16.76 17.44 16.39C19.75 14.4 21.92 12.3 24 19.16C24 19.16 23.72 19.65 23.29 20.29C22.6 21.29 21.7 22.4 20.7 23C19.74 23.56 18.4 23.83 17.72 23.93C16.97 24.03 15.53 24 3.99 23.97C3.75 23.96 3.45 23.95 3.17 23.91C2.3 23.77 0.99 23.18 1 21.94C1.01 20.72 2.16 20.02 3.11 19.61C3.88 19.27 4.78 19.25 5.46 19.45C6.01 19.61 6.16 19.81 6.44 20.09C6.75 20.39 6.84 20.7 6.8 21.02C6.74 21.48 6.32 21.83 5.97 21.99C5.56 22.18 4.98 22.24 4.56 22.08C4.14 21.92 4.45 21.51 4.03 21.31C3.86 21.23 3.55 21.29 3.4 21.37C3.22 21.47 3.08 21.65 3.1 21.86C3.14 22.3 3.71 22.53 4.07 22.6C4.92 22.78 5.86 22.63 6.64 22.45C7.09 22.34 7.54 22.17 7.92 21.91C8.29 21.65 8.61 21.3 8.77 20.9C8.91 20.52 8.91 20.13 8.84 19.75C8.72 19.11 8.29 18.56 7.87 18.16C6.87 17.2 5.7 16.98 4.44 17.16C3.43 17.3 2.54 17.71 1.79 18.31C1.03 18.92 0.38 19.81 0.2 20.85C0.07 21.63 0.27 22.36 0.68 22.96C1.13 23.62 1.86 24.04 2.61 24.27C3.33 24.49 4.1 24.51 4.88 24.49C5.41 24.48 5.93 24.4 16.52 24.5C18.36 24.52 19.37 24.39 20.29 24.25C21.33 24.08 22.36 23.76 23.17 23.31C24.04 22.83 24.75 22.16 25.29 21.49C25.8 20.86 26.16 20.19 26.36 19.62C26.73 18.6 26.62 17.84 26.3 17.31C25.96 16.76 25.39 16.49 24.99 16.35C24.03 16.04 22.93 16.07 22.06 16.47C21.21 16.86 20.67 17.64 20.63 18.57C20.6 19.33 20.92 20.06 21.46 20.46C21.98 20.86 22.73 21.02 23.4 20.87C23.76 20.79 24.08 20.61 24.3 20.3C24.48 20.03 24.57 19.69 24.54 19.34C24.49 18.84 24.11 18.44 23.69 18.18C23.26 17.93 22.75 17.8 22.23 17.79C21.16 17.79 20.26 18.38 20 19.39C19.86 20.01 20.05 20.62 20.37 21.1C20.7 21.58 21.17 21.92 21.74 22.14C22.3 22.35 22.93 22.45 23.56 22.42C24.18 22.39 24.81 22.22 25.34 21.92C25.86 21.64 26.29 21.24 26.59 20.74C26.89 20.23 27 19.64 26.96 19C26.86 17.66 25.96 16.57 24.77 15.94C23.56 15.29 22.07 15.2 20.86 15.68C19.64 16.16 18.79 17.19 18.55 18.43C18.44 18.98 18.5 19.53 18.67 20.05C18.9 20.7 19.31 21.25 19.86 21.67C20.4 22.09 21.09 22.36 21.81 22.47C22.53 22.59 23.29 22.53 23.99 22.29C24.76 22.03 25.42 21.49 24.21 21.29C23.77 21.22 23.05 21.27 23.07 20.68C23.09 20.21 23.53 20.03 23.95 20.06C24.49 20.1 25.01 20.4 25.19 20.92C25.38 21.46 25.12 22.06 24.71 22.4C24.2 22.83 23.49 23.04 22.81 23.02C22.13 22.99 21.48 22.75 20.97 22.32C20.45 21.88 20.1 21.24 19.98 20.56C19.88 19.94 19.96 19.28 20.23 18.71C20.78 17.55 22.28 16.94 23.6 17.37C24.36 17.61 24.96 18.12 25.3 18.8C25.5 19.22 25.57 19.69 25.51 20.17C25.44 20.7 25.18 21.19 24.77 21.57C24.37 21.95 23.83 22.2 23.26 22.3C22.72 22.4 22.12 22.33 21.61 22.14C21.1 21.95 20.67 21.64 20.35 21.24C20.02 20.84 19.82 20.34 19.76 19.83C19.65 19.04 19.85 18.18 20.34 17.56C21.32 16.29 23.24 16"40e18.24C24.37 18.52 24.86 19.19 25.05 19.75C25.25 20.33 25.15 20.97 24.85 21.52C24.54 22.08 24.06 22.53 23.47 22.8C22.89 23.07 22.21 23.14 21.57 23.03C20.93 22.91 20.33 22.62 19.86 22.19C19.39 21.76 19.05 21.19 18.88 20.57C18.71 19.94 18.73 19.25 18.93 18.64C19.32 17.44 20.36 16.55 21.57 16.16C22.77 15.76 24.16 15.86 25.26 16.42C26.36 16.99 27.2 18.01 27.39 19.19C27.47 19.77 27.41 20.36 27.19 20.91C26.97 21.45 26.6 21.93 26.13 22.31C25.65 22.68 25.05 22.95 24.41 23.09C23.76 23.22 23.08 23.21 22.43 23.07C21.77 22.92 21.15 22.64 20.64 22.23C20.13 21.82 19.74 21.28 19.51 20.68C19.28 20.08 19.23 19.42 19.36 18.8C19.61 17.57 20.46 16.53 21.58 15.97C23.02 15.24 24.83 15.31 26.2 16.18C26.93 16.62 27.49 17.26 27.83 18.03C28.14 18.75 28.22 19.56 28.02 20.34C27.84 21.1 27.37 21.8 26.76 22.3C26.15 22.8 25.41 24.1 24.58 23.19C23.73 23.27 22.85 23.13 22.07 22.79C21.28 22.44 20.62 21.89 20.2 21.2C19.78 20.5 19.63 19.7 19.75 18.91C19.88 18.12 20.26 17.39 20.86 16.82C22.04 15.71 23.81 15.48 25.22 16.08C25.93 16.38 26.54 16.88 26.98 17.52C27.43 18.16 27.69 18.92 27.69 19.7C27.69 20.77 27.2 21.8 26.43 22.52C25.66 23.23 24.64 23.61 23.59 23.64C22.55 23.66 21.51 23.34 20.75 22.72C20.37 22.41 20.05 22.02 19.83 21.59C19.6 21.16 19.47 20.69 19.42 20.2C19.3 19.23 19.59 18.24 20.2 17.51C20.81 16.77 21.71 16.31 22.68 16.23C23.64 16.16 24.64 16.44 25.4 17.02C26.17 17.61 26.67 18.48 26.75 19.41C26.83 20.34 26.48 21.27 25.85 21.97C25.22 22.67 24.32 23.09 23.38 23.15C22.45 23.21 21.5 22.91 20.8 22.32C20.09 21.72 19.65 20.84 19.58 19.9C19.55 19.44 19.62 18.97 19.79 18.54C19.95 18.11 20.21 17.73 20.54 17.42C21.21 16.8 22.15 16.51 23.04 16.62C23.94 16.74 24.76 17.25 25.22 17.99C25.69 18.73 25.79 19.66 25.51 20.49C25.24 21.32 24.61 22.01 23.8 22.39C22.98 22.77 22.02 22.83 21.15 22.56C20.28 22.29 19.55 21.71 19.16 20.93C18.72 20.18 18.29 18.76"19.84 17.55C19.93 17.53 19.99 17.44 20.07 17.44C20.47 17.41 21.02 17.55 21.39 17.8C21.48 17.86 21.59 17.95 21.7 18.05C21.81 18.16 21.91 18.28 22.01 18.42C22.36 18.85 22.51 19.42 22.42 19.98C22.34 19.93 22.32 19.86 22.27 19.8C22.21 19.7 22.15 19.6 22.07 19.5C22.06 19.55 21.88 19.7 21.86 19.72L21.23 20.14L20.55 20.32C20.37 20.39 20.18 20.42 20 20.41C19.46 20.38 19.01 19.97 18.86 19.47C18.77 19.19 18.78 18.88 18.88 18.6C19 18.3 19.19 18.04 19.43 17.85C20.07 17.32 21.05 17.17 21.87 17.37C22.03 17.42 22.2 17.51 22.34 17.63C22.79 17.99 23.04 18.55 23.02 19.15C23 19.67 22.76 20.17 22.36 20.53C21.51 21.28 20.08 21.34 19.15 20.71C18.23 20.08 17.94 18.91 18.33 17.97C18.64 17.21 19.34 16.69 20.14 16.55C20.95 16.42 21.83 16.66 22.42 17.22C23.01 17.77 23.29 18.6 23.17 19.42C23.06 20.23 22.56 20.96 21.85 21.4C21.13 21.85 20.21 21.97 19.39 21.74C18.57 21.51 17.92 20.96 17.57 20.23C17.21 19.5 17.19 18.62 17.51 17.87C17.82 17.12 18.48 16.54 19.27 16.31C20.07 16.08 20.96 16.22 21.66 16.66C22.36 17.11 22.81 17.85 22.91 18.66C23.01 19.48 22.75 20.31 22.19 20.92C21.63 21.54 20.8 21.9 20.01 21.95C19.21 22 18.41 21.73 17.83 21.2C17.24 20.67 16.92 19.89 16.96 19.1C17 18.3 17.4 17.57 18.04 17.13C18.68 16.69 19.53 16.55 20.3 16.74C21.06 16.94 21.71 17.46 22.06 18.16C22.4 18.86 22.43 19.71 22.12 20.44C21.81 21.16 21.19 21.74 20.44 22.02C19.69 22.29 18.83 22.27 18.09 21.93C17.35 21.6 16.83 20.96 16.65 20.21C16.36 18.99 17.07 17.71 18.22 17.15C19.22 16.66 20.45 16.84 21.28 17.56C22.12 18.28 22.43 19.5 22.05 20.57C21.66 21.63 20.69 22.41 19.55 22.64C19.06 22.74 18.54 22.72 18.06 22.6C17.58 22.48 17.14 22.25 16.78 21.95C16.06 21.34 15.64 20.41 15.68 19.45C15.71 18.49 16.19 17.59 16.95 17.02C17.7 16.45 18.71 16.22 19.62 16.42C20.54 16.61 21.32 17.21 21.74 18.02C22.16 18.83 22.18 19.82 21.81 20.65C21.43 21.48 20.69 22.13 19.85 22.37C19 22.61 18.08 22.43 17.35 21.89C16.62 21.34 16.2 20.46 16.24 19.54C16.28 18.62 16.77 17.77 17.52 17.28C18.27 16.79 19.26 16.66 20.14 16.92C21.03 17.18 21.75 17.82 22.09 18.67C22.42 19.52 22.35 20.5 21.9 21.28C21.45 22.06 20.65 22.61 19.74 22.77C18.84 22.92 17.89 22.67 17.17 22.08C16.44 21.49 16 20.6 15.98 19.66C15.96 18.71 16.33 17.8 17.02 17.17C17.71 16.54 18.66 16.24 19.59 16.37C20.52 16.51 21.35 17.06 21.82 17.83C22.3 18.6 22.39 19.58 22.07 20.44C21.75 21.3 21.05 22 20.19 22.35C19.34 22.7 18.35 22.68 17.51 22.28C16.67 21.89 16.06 21.14 15.84 20.25C15.43 18.45 16.55 16.62 18.34 16.12C19.23 15.87 20.21 16.04 20.97 16.58C21.73 17.13 22.21 17.98 22.26 18.91C22.32 19.84 21.96 20.76 21.28 21.39C20.61 22.02 19.66 22.31 18.77 22.18C17.87 22.05 17.09 21.51 16.67 20.73C16.25 19.95 16.23 19.02 16.61 18.21C16.99 17.41 17.74 16.84 18.61 16.66C19.48 16.48 20.41 16.7 21.09 17.26C21.77 17.81 22.17 18.67 22.19 19.58C22.21 20.49 21.83 21.36 21.17 21.93C20.51 22.5 19.6 22.75 18.71 22.61C17.83 22.47 17.06 21.96 16.64 21.23C16.21 20.5 16.14 19.62 16.45 18.83C16.76 18.04 17.43 17.41 18.24 17.12C19.05 16.83 19.97 16.91 20.71 17.33C21.45 17.75 21.97 18.48 22.14 19.32C22.31 20.15 22.11 21.05 21.61 21.72C21.1 22.39 20.3 22.8 19.45 22.84C18.6 22.89 17.77 22.57 17.16 22C16.54 21.42 16.22 20.63 16.22 19.78C16.22 18.93 16.55 18.13 17.17 17.56C17.79 16.99 18.62 16.68 19.45 16.73C20.28 16.79 21.06 17.19 16.57 17.83C22.09 18.48 22.29 19.36 22.12 20.18C21.96 20.99 21.43 21.7 20.69 22.11C19.95 22.51 19.04 22.57 22.23 22.27C17.41 21.97 16.81 21.3 16.6 19.47C16.39 19.04 16.42 18.57 16.55 18.14C16.69 17.71 16.94 17.33 17.26 17.03C17.9 16.43 18.78 16.13 19.66 16.24C20.53 16.35 21.34 16.87 21.76 17.63C22.18 18.38 22.2 19.3 21.83 20.07C21.45 20.84 20.71 21.41 19.84 21.6C18.98 21.78 18.04 21.56 17.36 20.99C16.67 20.43 16.28 19.57 26.35 18.7C16.41 17.84 16.9 17.22 17.83 17.65C22.4.1 22.47 18.77 22.5 19.71C22.53 20.16 22.47 20.62 22.33 21.05C22.2 21.48 21.98 21.86 21.69 18.17C21.09 22.81 20.21 23.13 29.28 22.99C18.36 22.86 17.46 22.45 16.85 21.72C16.24 21 15.97 20.04 16.1 19.1C16.23 18.17 16.74 17.31 17.52 16.76C18.29 16.21 19.32 15.93 20.27 16.15C21.22 16.37 22.07 17.09 22.39 18C22.74 18.99 22.51 20.11 21.82 20.86C21.12 21.61 20.04 21.92 19.04 19.75C18.04 16.57 17.37 16.25 20.84 17.99C16.33 17.42 16.09 17.17 16.0 17.04C15.54 16.92 15.16 16.92 14.84 17.04C14.52 17.17 14.26 17.42 14.14 17.75C14.03 18.08 14.06 18.46 14.24 18.77C14.43 19.08 14.74 19.31 15.12 19.41C15.7 19.58 16.4 19.41 16.85 12.96C17.3 12.51 17.48 11.85 17.35 11.27C17.21 10.69 16.78 10.24 16.18 10.1C15.59 9.96 14.95 10.14 14.51 10.59C14.07 11.03 13.89 11.68 14.02 12.26C14.15 12.84 14.59 13.29 15.18 19.44C15.78 19.58 16.42 19.4 16.86 18.96C17.3 18.53 17.48 17.88 17.35 17.3C17.22 16.72 16.78 16.27 16.19 16.13C15.36 16.93 14.83 13.99 14.64 14.79C14.44 15.59 14.7 16.46 15.31 17.07C15.91 17.67 16.79 17.94 17.59 17.75C18.39 17.55 19.03 16.95 19.21 16.17C19.47 14.98 18.82 13.72 17.67 13.17C16.53 12.61 15.1 12.84 14.25 13.72C13.39 14.59 13.21 16.06 13.85 17.2C14.3 17.97 15.14 18.51 16.07 18.61C17 18.71 17.95 18.37 18.65 17.71C19.07 17.31 19.36 16.78 19.46 16.2C19.63 15.29 19.42 14 8.93 14.92C18.43 15.85 17.69 16.98 16.83 17.82C15.98 18.67 14.79 19.11 13.63 18.99C12.46 18.88 11.4 18.21 10.77 17.22C9.56 15.49 9.79 13.02 11.34 11.57C12.89 10.12 15.32 10.2 16.77 11.75C17.53 12.6 17.91 13.73 17.87 14.86C17.82 15.99"17.36 17.09 16.59 17.9C15.82 18.71 13.28 19.24 35.75 19.22C11.82 19.19 10.63 18.62 9.84 17.77C9.05 16.91 8.68 15.76 8.83 14.61C8.99 13.47 9.63 12.45 10.58 11.81C12.48 10.54 15.02 11.09 16.3 12.98C17.57 14.88 17.07 17.44 15.24 18.73C14.34 19.39 13.21 19.66 12.14 19.47C11.07 19.27 10.14 18.64 9.56 17.74C3.38 14.95 9.07 12.08 10.49 10.58C11.9 9.08 14.02 8.62 15.87 9.38C17.72 10.14 18.95 11.96 18.98 14Dz" fill="#AF2124"/></svg>" width="24" alt="OpenAI"><br><small>OpenAI</small></div>
                <div style="text-align: center;"><img src="data:image/svg+xml;base64,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" width="24" alt="Claude"><br><small>Claude</small></div>
                <div style="text-align: center;"><img src="data:image/svg+xml;base64,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" width="24" alt="Perplexity"><br><small>Perplexity</small></div>
            </div>
            """
            , unsafe_allow_html=True)
            
            model_options = [
                # Gemini models with their specific versions and exact call signs
                "Gemini - 2.5 Pro (gemini-2.5-pro-preview-03-25)",
                "Gemini - 2.0 Flash (gemini-2.0-flash-001)",
                "Gemini - 2.0 Flash-Lite (gemini-2.0-flash-lite-001)",
                "Gemini - 1.5 Pro (gemini-1.5-pro-001)",
                "Gemini - 1.5 Flash (gemini-1.5-flash-001)",
                "Gemini - 1.5 Flash-8B (gemini-1.5-flash-8b-001)",
                
                # Gemini Live API models
                "Gemini - 2.0 Flash Live (gemini-2.0-flash-live-preview-04-09)",
                
                # Vertex AI models
                "Vertex AI - Claude 3.5 Sonnet (claude-3-5-sonnet-20241022)",
                "Vertex AI - Claude 3 Opus (claude-3-opus-20240229)",
                "Vertex AI - GPT-4o (gpt-4o)",
                
                # Direct API models
                "OpenAI - GPT-4o (gpt-4o)",
                "Anthropic - Claude 3.5 Sonnet (claude-3-5-sonnet-20241022)",
                "Anthropic - Claude 3 Opus (claude-3-opus-20240229)",
                
                # Perplexity models
                "Perplexity - 70B Online (pplx-70b-online)",
                "Perplexity - 7B Online (pplx-7b-online)",
                "Perplexity - 70B Chat (pplx-70b-chat)"
            ]
            
            # Find the closest match in model_options for current_model
            current_index = 0
            if st.session_state.current_model:
                for i, option in enumerate(model_options):
                    if st.session_state.current_model in option:
                        current_index = i
                        break
            
            selected_model = st.selectbox(
                "Select AI model",
                options=model_options,
                index=current_index,
                label_visibility="collapsed",
                key="model_selector"
            )
            
            if selected_model != st.session_state.current_model:
                # Model changed - attempt to load most recent chat for this model
                chat_id, messages = get_most_recent_chat(st.session_state.user, selected_model)
                
                # Update session state with new model
                st.session_state.current_model = selected_model
                
                # Update chat_id in session state
                st.session_state.chat_id = chat_id
                
                # Update messages if found for this model
                if messages:
                    st.session_state.messages = messages
                    st.info(f"Loaded most recent {selected_model} chat")
                else:
                    # If no chat exists for this model, start a new one
                    st.session_state.messages = []
                    st.info(f"Started a new {selected_model} chat")
                
                # Clear uploaded image when switching models
                st.session_state.uploaded_image = None
                
                # Force a rerun to refresh the chat
                st.rerun()
            
            # Model settings based on selection with enhanced UI
            st.markdown("""
            <div style="margin-top: 20px; padding-top: 15px; border-top: 1px solid #333;">
                <p style="font-weight: 500; margin-bottom: 5px; color: #4285f4;">Response Settings</p>
            </div>
            """, unsafe_allow_html=True)
            
            # Show temperature control for all models except Claude/Anthropic which have fixed settings
            if "anthropic" not in st.session_state.current_model.lower():
                st.write("Temperature")
                
                # Create two columns for min/max labels
                temp_label_cols = st.columns([1, 1])
                with temp_label_cols[0]:
                    st.markdown("<p style='color: #888; font-size: 0.8rem; margin: 0;'>Precise</p>", unsafe_allow_html=True)
                with temp_label_cols[1]:
                    st.markdown("<p style='color: #888; font-size: 0.8rem; text-align: right; margin: 0;'>Creative</p>", unsafe_allow_html=True)
                
                temperature = st.slider(
                    "Select temperature", 
                    0.0, 1.0, 
                    st.session_state.temperature, 
                    0.1, 
                    label_visibility="collapsed"
                )
                if temperature != st.session_state.temperature:
                    st.session_state.temperature = temperature
                
                # Additional model options
                st.write("Output tokens")
                max_tokens = st.slider("Max tokens", 100, 1500, 800, 100, label_visibility="collapsed")
                
            # Add New Chat button
            st.markdown("""
            <div style="margin-top: 30px; padding-top: 15px; border-top: 1px solid #333; margin-bottom: 10px;">
                <p style="font-weight: 500; margin-bottom: 5px; color: #4285f4;">Chat Actions</p>
            </div>
            """, unsafe_allow_html=True)
            
            if st.button("New Chat", use_container_width=True):
                # Clear messages but keep other settings
                st.session_state.messages = []
                st.session_state.chat_id = None
                # Visual confirmation
                st.success("Started a new chat!")
                st.rerun()
            
            # Features with toggle buttons styled like Google AI Studio
            st.subheader("Features")
            multi_turn = st.toggle("Multi-turn conversation", value=True)
            
            # Add visual examples of capabilities like in Google AI Studio
            st.subheader("Capabilities")
            capabilities_cols = st.columns(3)
            with capabilities_cols[0]:
                st.markdown("‚å®Ô∏è Text & Code")
            with capabilities_cols[1]:
                st.markdown("üñºÔ∏è Images")
            with capabilities_cols[2]:
                st.markdown("üîä Audio")
            
            # Current user info
            st.subheader("User")
            st.write(f"Current user: {st.session_state.user}")
            
            # Voice Command UI
            st.markdown("""
            <div style="margin-top: 30px; border-top: 1px solid #333; padding-top: 15px;">
            </div>
            """, unsafe_allow_html=True)
            
            # Render voice command UI with toggle function
            render_voice_command_ui(
                voice_active=st.session_state.voice_commands_active,
                toggle_callback=toggle_voice_commands,
                is_listening=st.session_state.is_listening
            )
            
            # Render floating voice button if active
            if st.session_state.voice_commands_active:
                render_floating_voice_button(st.session_state.is_listening)
            
            # Logout button
            if st.button("Logout", use_container_width=True):
                # Clean up voice processor before logout
                if st.session_state.voice_processor:
                    st.session_state.voice_processor.stop_listening()
                    st.session_state.voice_processor = None
                    st.session_state.is_listening = False
                logout_user()
                st.rerun()
            
            # Load previous conversations with a better filing system
            st.subheader("Chat Library")
            
            # Add search box for filtering conversations
            search_term = st.text_input("Search chats by model or content", key="chat_search")
            
            # Get all conversations
            previous_conversations = load_conversations(st.session_state.user)
            
            if previous_conversations:
                # Group conversations by model
                model_groups = {}
                for convo in previous_conversations:
                    model = convo.get("model", "Unknown model")
                    if model not in model_groups:
                        model_groups[model] = []
                    model_groups[model].append(convo)
                
                # Display groups in expandable sections
                for model, convos in model_groups.items():
                    # Skip if search term is provided and not found in model name
                    if search_term and search_term.lower() not in model.lower():
                        # Try to search in conversation content
                        found_content = False
                        for convo in convos:
                            messages = convo.get("messages", [])
                            for msg in messages:
                                if search_term.lower() in msg.get("content", "").lower():
                                    found_content = True
                                    break
                            if found_content:
                                break
                        if not found_content:
                            continue
                    
                    with st.expander(f"{model} ({len(convos)} chats)", expanded=False):
                        # Sort conversations by date
                        sorted_convos = sorted(
                            convos, 
                            key=lambda x: x.get("last_updated", x.get("timestamp", "1900-01-01")),
                            reverse=True
                        )
                        
                        for idx, convo in enumerate(sorted_convos):
                            timestamp = convo.get("last_updated", convo.get("timestamp", "Unknown date"))
                            chat_id = convo.get("id")
                            
                            # Format timestamp for better readability
                            try:
                                datetime_obj = datetime.datetime.strptime(timestamp, "%Y-%m-%d %H:%M:%S")
                                formatted_time = datetime_obj.strftime("%m/%d %H:%M")
                            except:
                                formatted_time = timestamp
                            
                            # Get a preview of the last message for context
                            messages = convo.get("messages", [])
                            preview = ""
                            if messages:
                                last_msg = messages[-1].get("content", "")
                                preview = last_msg[:30] + "..." if len(last_msg) > 30 else last_msg
                            
                            # Display the timestamp and preview on the same line (no nested columns)
                            st.write(f"**{formatted_time}** - _{preview}_")
                            
                            if st.button(f"Load Chat", key=f"convo_{model}_{idx}"):
                                # Load this conversation
                                st.session_state.messages = convo.get("messages", [])
                                st.session_state.current_model = model
                                st.session_state.chat_id = chat_id  # Store the chat ID for future updates
                                st.success(f"Loaded chat from {formatted_time}")
                                st.rerun()
                            
                            if idx < len(sorted_convos) - 1:
                                st.markdown("---")
            else:
                st.write("No previous conversations found")
                
            # Footer info with Google AI Studio style
            st.markdown("---")
            st.markdown("AI Chat Studio | 2024")

# Run the app
# Clean up function for voice commands when the app exits
def cleanup_on_exit():
    """Clean up resources when the app exits"""
    # Stop voice processor if running
    if hasattr(st.session_state, 'voice_processor') and st.session_state.voice_processor:
        try:
            st.session_state.voice_processor.stop_listening()
            print("Stopped voice command processor")
        except:
            pass
    
    # Clean up any temporary audio files
    if hasattr(st.session_state, 'audio_path') and st.session_state.audio_path:
        try:
            from utils.audio import cleanup_audio_file
            cleanup_audio_file(st.session_state.audio_path)
        except:
            pass

if __name__ == "__main__":
    try:
        main()
    finally:
        # Execute cleanup when the app exits
        cleanup_on_exit()
