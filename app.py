import streamlit as st
import os
import datetime
import json
import base64
import tempfile
import threading
import html
from io import BytesIO
from PIL import Image
from utils.ui_components import render_voice_command_ui, render_floating_voice_button
from utils.themes import apply_theme, THEMES
# Emoji picker removed to fix chat functionality
from utils.models import (
    get_gemini_response,
    get_vertex_ai_response,
    get_openai_response,
    get_anthropic_response,
    get_perplexity_response
)
# Use Google OAuth for secure authentication
from utils.google_auth import check_login, logout_user, get_current_user, is_admin
from utils.database import init_db, save_conversation, load_conversations, get_most_recent_chat
# Enhanced audio recording with WebRTC
from utils.webrtc_audio import audio_recorder_ui
# Text-to-speech with ElevenLabs
from utils.tts import render_tts_controls, render_play_button, text_to_speech

# Set page configuration
st.set_page_config(
    page_title="AI Chat Studio",
    page_icon="assets/favicon.svg",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Initialize session state variables
if "messages" not in st.session_state:
    st.session_state.messages = []
if "user" not in st.session_state:
    st.session_state.user = None
if "current_model" not in st.session_state:
    st.session_state.current_model = "Gemini"
if "voice_commands_enabled" not in st.session_state:
    st.session_state.voice_commands_enabled = False
if "voice_commands_active" not in st.session_state:
    st.session_state.voice_commands_active = False
if "temperature" not in st.session_state:
    st.session_state.temperature = 0.7
if "uploaded_image" not in st.session_state:
    st.session_state.uploaded_image = None
    
# Voice command state variables
if "voice_commands_active" not in st.session_state:
    st.session_state.voice_commands_active = False
if "voice_processor" not in st.session_state:
    st.session_state.voice_processor = None
if "is_listening" not in st.session_state:
    st.session_state.is_listening = False
    
# Theme state - initialize before use
if "current_theme" not in st.session_state:
    st.session_state.current_theme = "Amazon Q Purple"
    
# Message cooldown to prevent double-sending
if "message_cooldown" not in st.session_state:
    st.session_state.message_cooldown = False

# Apply the current theme's CSS
theme_css = apply_theme(st.session_state.current_theme)
st.markdown(theme_css, unsafe_allow_html=True)

# Check user login
check_login()

# Helper function to encode image for API calls
def encode_image(uploaded_file):
    if uploaded_file is not None:
        # Read the file and encode it
        bytes_data = uploaded_file.getvalue()
        
        # Convert to base64
        encoded = base64.b64encode(bytes_data).decode('utf-8')
        return encoded
    return None

# Main function
def main():
    # Initialize database
    init_db()
    
    # Apply custom styling to match Google Gemini UI exactly
    st.markdown("""
    <style>
    /* Dark background for the app */
    .stApp {
        background-color: #0e1117;
    }
    
    /* Left sidebar styling */
    [data-testid="stSidebar"] {
        background-color: #0e1117;
        border-right: 1px solid #333;
    }
    
    /* Hide default Streamlit hamburger menu */
    section[data-testid="stSidebarUserContent"] {
        padding-top: 0rem;
    }
    
    /* Make the main content full width */
    .main .block-container {
        max-width: 100%;
        padding-top: 1rem;
        padding-left: 1rem;
        padding-right: 1rem;
    }
    
    /* Right sidebar styling */
    .right-sidebar {
        position: fixed;
        right: 0;
        top: 0;
        width: 250px;
        height: 100vh;
        padding: 1rem;
        background-color: #0e1117;
        border-left: 1px solid #333;
        overflow-y: auto;
        z-index: 10;
    }
    
    /* Main content area with space for the right sidebar */
    .main-content {
        margin-right: 250px;
    }
    
    /* Toggle button styling */
    .toggle-container {
        margin-top: 5px;
    }
    .toggle-button {
        background-color: #333;
        border-radius: 15px;
        display: inline-block;
        height: 20px;
        position: relative;
        width: 40px;
    }
    .toggle-button.active {
        background-color: #4285f4;
    }
    .toggle-button::after {
        background-color: white;
        border-radius: 50%;
        content: '';
        height: 16px;
        left: 2px;
        position: absolute;
        top: 2px;
        transition: all 0.3s;
        width: 16px;
    }
    .toggle-button.active::after {
        left: 22px;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # Left sidebar matching the Google Gemini interface
    with st.sidebar:
        # App selector at top
        st.text_input("app", value="Gemini Studio", disabled=True, label_visibility="collapsed")
        
        # Gemini Studio link
        st.markdown("""
        <div style="padding: 10px 0; cursor: pointer;">
            <span style="color: white; font-weight: 500;">Gemini Studio</span>
        </div>
        """, unsafe_allow_html=True)
        
        # Chat Library section
        st.markdown("""
        <div style="margin-top: 20px; margin-bottom: 10px;">
            <span style="color: #888; font-size: 14px; font-weight: 500;">CHAT LIBRARY</span>
        </div>
        """, unsafe_allow_html=True)
        
        # Search input
        search_text = st.text_input("Search chats", key="search_chats", placeholder="Search for past prompts")
        
        # Display message if no chats are found
        st.markdown("""
        <div style="color: #888; font-size: 12px; padding: 5px 0;">
            No previous conversations found
        </div>
        """, unsafe_allow_html=True)
        
        # Horizontal separator
        st.markdown("<hr style='margin: 20px 0; border-color: #333;'>", unsafe_allow_html=True)
        
        # Capabilities section
        st.markdown("""
        <div style="margin-bottom: 10px;">
            <span style="color: #888; font-size: 14px; font-weight: 500;">CAPABILITIES</span>
        </div>
        """, unsafe_allow_html=True)
        
        # Capabilities list
        st.markdown("""
        <div style="padding: 5px 0;">
            <span style="color: white;">üìù Text & Code</span>
        </div>
        <div style="padding: 5px 0;">
            <span style="color: white;">üñºÔ∏è Images</span>
        </div>
        <div style="padding: 5px 0;">
            <span style="color: white;">üîä Audio</span>
        </div>
        """, unsafe_allow_html=True)
        
        # Logout button at bottom
        st.markdown("<div style='margin-top: 30px;'></div>", unsafe_allow_html=True)
        if st.button("Logout", use_container_width=True, type="primary", key="logout_bottom"):
            logout_user()
            st.rerun()
    
    # Right sidebar for tools panel exactly as in Google Gemini
    right_col = st.container()
    
    # Create a column layout - main content and right sidebar
    main_content, right_sidebar = st.columns([7, 2])
    
    # Main content area with chat UI
    with main_content:
        # Main chat area with exactly the header shown in the screenshot
        st.markdown("""
        <div style="text-align: center; padding: 20px 0;">
            <h1 style="font-size: 2.2rem; margin-bottom: 5px; color: white;">Talk with AI live</h1>
            <p style="color: #888; font-size: 1.1rem;">Interact with AI models using text, code, images, audio, or upload files</p>
        </div>
        """, unsafe_allow_html=True)
        
        # Model display box exactly as shown in the screenshot
        st.markdown("""
        <div style="max-width: 600px; margin: 10px auto; padding: 10px; background-color: rgba(20, 20, 20, 0.6); border-radius: 8px; border: 1px solid #333;">
            <p style="margin: 0; color: #4285f4; text-align: center;">
                <span style="color: #4285f4; font-weight: normal;">Model:</span> <span style="color: #4285f4;">Gemini 2.0 Pro (gemini-1.5-pro)</span>
            </p>
        </div>
        """, unsafe_allow_html=True)
        
        # Add custom CSS for improved message container
        st.markdown("""
        <style>
        .chat-container {
            height: 600px !important;
            overflow-y: auto;
            padding-right: 15px;
            margin-bottom: 20px;
            border-radius: 10px;
            background-color: rgba(40, 40, 40, 0.2);
        }
        .stChatInputContainer {
            min-height: 80px !important;
            padding: 10px !important;
            margin-top: 15px !important;
        }
        .stChatInput {
            min-height: 60px !important;
            font-size: 16px !important;
        }
        </style>
        """, unsafe_allow_html=True)
        
        # Create a taller fixed-height container for chat messages with Google AI Studio style
        chat_container = st.container(height=600, border=False)
        st.markdown('<div class="chat-container">', unsafe_allow_html=True)
        
        # Display chat messages in a clean Google AI Studio style within the fixed container
        with chat_container:
            for i, message in enumerate(st.session_state.messages):
                # Custom styling for messages based on role
                if message["role"] == "user":
                    # User message with custom styling
                    st.markdown(f"""
                    <div style="display: flex; align-items: start; margin-bottom: 10px;">
                        <div style="background-color: #f50057; color: white; border-radius: 50%; height: 32px; width: 32px; display: flex; align-items: center; justify-content: center; margin-right: 10px; flex-shrink: 0;">
                            <span>üë§</span>
                        </div>
                        <div style="background-color: #1e1e1e; border-radius: 10px; padding: 10px; max-width: 90%;">
                            <p style="margin: 0; color: white; white-space: pre-wrap;">{html.escape(message["content"]).replace(chr(10), '<br>')}</p>
                        </div>
                    </div>
                    """, unsafe_allow_html=True)
                
                # If there's an image in the message
                if message.get("image"):
                    try:
                        # Display the image below the text
                        image_data = base64.b64decode(message["image"])
                        image = Image.open(BytesIO(image_data))
                        st.image(image, caption="Uploaded Image", width=300)
                    except Exception as e:
                        st.error(f"Could not display image: {str(e)}")
                else:
                    # AI message with custom styling
                    st.markdown(f"""
                    <div style="display: flex; align-items: start; margin-bottom: 10px;">
                        <div style="background-color: #8c52ff; color: white; border-radius: 50%; height: 32px; width: 32px; display: flex; align-items: center; justify-content: center; margin-right: 10px; flex-shrink: 0;">
                            <span>ü§ñ</span>
                        </div>
                        <div style="background-color: #272727; border-radius: 10px; padding: 10px; max-width: 90%;">
                            <p style="margin: 0; color: white; white-space: pre-wrap;">{html.escape(message["content"]).replace(chr(10), '<br>')}</p>
                        </div>
                    </div>
                    """, unsafe_allow_html=True)
                    
                    # Add text-to-speech and reaction buttons for AI messages
                    if i > 0 and message["role"] == "assistant":
                        # Create a unique key for each message's reaction section
                        message_key = f"reaction_{i}"
                        
                        # Initialize reaction counts in session state if not already set
                        if message_key not in st.session_state:
                            st.session_state[message_key] = {"üëç": 0, "‚ù§Ô∏è": 0, "üòÇ": 0, "üòÆ": 0, "üî•": 0}
                        
                        # Display the reactions as small text instead of buttons
                        reaction_html = ""
                        reactions = ["üëç", "‚ù§Ô∏è", "üòÇ", "üòÆ", "üî•"]
                        
                        for emoji in reactions:
                            count = st.session_state[message_key][emoji]
                            reaction_html += f"<span style='margin-right:8px;font-size:15px;'>{emoji} {count if count > 0 else ''}</span>"
                        
                        # Show them in a clean HTML layout
                        st.markdown(f"""
                        <div style="margin-top:5px;margin-bottom:10px;margin-left:40px;">
                            {reaction_html}
                        </div>
                        """, unsafe_allow_html=True)
                        
                        # Add buttons row: Play (TTS), Copy, and React
                        tts_col, react_col, copy_col = st.columns([1, 1, 2])
                        
                        # Text-to-speech button
                        with tts_col:
                            # Use the render_play_button from utils/tts.py
                            render_play_button(message["content"], key=f"tts_{i}")
                        
                        # React button
                        if react_col.button("üëç React", key=f"react_btn_{i}", use_container_width=True):
                            st.session_state[message_key]["üëç"] += 1
                            
                        # Copy text button
                        if copy_col.button("üìã Copy Text", key=f"copy_btn_{i}", use_container_width=True):
                            # Use JavaScript to copy to clipboard via streamlit component
                            st.markdown(f"""
                            <script>
                                var textToCopy = {json.dumps(message["content"])};
                                navigator.clipboard.writeText(textToCopy);
                            </script>
                            """, unsafe_allow_html=True)
                            st.toast("Text copied to clipboard!")
                            
        
        # Close the chat container div
        st.markdown('</div>', unsafe_allow_html=True)
        
        # This chat input is handled by the main one at line ~678 (don't use duplicate keys)
        # Keeping this section as a placeholder
            
    # Right sidebar panel exactly like Google Gemini UI
    with right_sidebar:
        # 1. Model info
        st.markdown("""
        <div style="display: flex; align-items: center; margin-bottom: 15px;">
            <svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" fill="#888" viewBox="0 0 24 24">
                <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zm0 16H5V5h14v14z"/>
                <path d="M7 10h10v2H7z"/>
            </svg>
            <span style="margin-left: 10px; color: white; font-weight: 500;">Model</span>
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown("""
        <div style="background-color: #1e1e1e; border-radius: 8px; padding: 15px; margin-bottom: 20px;">
            <div style="font-size: 14px; color: white; font-weight: 500;">Gemini 2.0 Pro</div>
            <div style="font-size: 12px; color: #888; margin-top: 5px;">Preview (03-26)</div>
        </div>
        """, unsafe_allow_html=True)
        
        # 2. Token count
        st.markdown("""
        <div style="display: flex; align-items: center; margin-bottom: 15px; margin-top: 30px;">
            <svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" fill="#888" viewBox="0 0 24 24">
                <path d="M20 2H4c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h16c1.1 0 2-.9 2-2V4c0-1.1-.9-2-2-2zm-9 2h2v2h-2V4zM9 8h2v2H9V8zm-4 8h2v2H5v-2zm0-8h2v2H5V8zm0-4h2v2H5V4zm4 12h2v2H9v-2zm4 0h2v2h-2v-2zm0-4h2v2h-2v-2zm0-8h2v2h-2V4zm4 4h2v2h-2V8zm0 8h2v2h-2v-2zm0-4h2v2h-2v-2zm0-8h2v2h-2V4z"/>
            </svg>
            <span style="margin-left: 10px; color: white; font-weight: 500;">Token count</span>
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown("""
        <div style="color: #888; font-size: 14px; margin-bottom: 20px;">0 / 1048576</div>
        """, unsafe_allow_html=True)
        
        # 3. Temperature
        st.markdown("""
        <div style="display: flex; align-items: center; margin-bottom: 15px; margin-top: 30px;">
            <svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" fill="#888" viewBox="0 0 24 24">
                <path d="M15 13V5c0-1.66-1.34-3-3-3S9 3.34 9 5v8c-1.21.91-2 2.37-2 4 0 2.76 2.24 5 5 5s5-2.24 5-5c0-1.63-.79-3.09-2-4zm-4-8c0-.55.45-1 1-1s1 .45 1 1h-2z"/>
            </svg>
            <span style="margin-left: 10px; color: white; font-weight: 500;">Temperature</span>
        </div>
        """, unsafe_allow_html=True)
        
        # Temperature slider that matches the design
        temperature = st.slider(
            label="Temperature",
            min_value=0.0, 
            max_value=1.0, 
            value=0.7, 
            step=0.01,
            label_visibility="collapsed",
            key="temperature_sidebar"
        )
        
        if temperature != st.session_state.temperature:
            st.session_state.temperature = temperature
        
        # 4. Tools section
        st.markdown("""
        <div style="display: flex; align-items: center; margin-bottom: 15px; margin-top: 30px;">
            <svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" fill="#888" viewBox="0 0 24 24">
                <path d="M22.7 19l-9.1-9.1c.9-2.3.4-5-1.5-6.9-2-2-5-2.4-7.4-1.3L9 6 6 9 1.6 4.7C.4 7.1.9 10.1 2.9 12.1c1.9 1.9 4.6 2.4 6.9 1.5l9.1 9.1c.4.4 1 .4 1.4 0l2.3-2.3c.5-.4.5-1.1.1-1.4z"/>
            </svg>
            <span style="margin-left: 10px; color: white; font-weight: 500;">Tools</span>
        </div>
        """, unsafe_allow_html=True)
        
        # Toggle switches for tools - these match the exact design
        st.markdown("""
        <div style="margin-bottom: 15px;">
            <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 10px;">
                <span style="color: white; font-size: 14px;">Structured output</span>
                <div class="toggle-button"></div>
            </div>
            
            <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 10px;">
                <span style="color: white; font-size: 14px;">Code execution</span>
                <div class="toggle-button"></div>
            </div>
            
            <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 10px;">
                <span style="color: white; font-size: 14px;">Function calling</span>
                <div class="toggle-button"></div>
            </div>
            
            <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 10px;">
                <span style="color: white; font-size: 14px;">Grounding with Google Search</span>
                <div class="toggle-button"></div>
            </div>
        </div>
        """, unsafe_allow_html=True)
        
        # Additional actions section
        st.markdown("""
        <div style="margin-top: 30px;">
            <button style="width: 100%; background-color: transparent; border: 1px solid #555; border-radius: 4px; color: white; padding: 8px 0; font-size: 14px; display: flex; align-items: center; justify-content: center; margin-bottom: 10px; cursor: pointer;">
                <svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" fill="white" viewBox="0 0 24 24" style="margin-right: 8px;">
                    <path d="M19 13h-6v6h-2v-6H5v-2h6V5h2v6h6v2z"/>
                </svg>
                My Drive
            </button>
            
            <button style="width: 100%; background-color: transparent; border: 1px solid #555; border-radius: 4px; color: white; padding: 8px 0; font-size: 14px; display: flex; align-items: center; justify-content: center; margin-bottom: 10px; cursor: pointer;">
                <svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" fill="white" viewBox="0 0 24 24" style="margin-right: 8px;">
                    <path d="M9 16h6v-6h4l-7-7-7 7h4zm-4 2h14v2H5z"/>
                </svg>
                Upload File
            </button>
            
            <button style="width: 100%; background-color: transparent; border: 1px solid #555; border-radius: 4px; color: white; padding: 8px 0; font-size: 14px; display: flex; align-items: center; justify-content: center; margin-bottom: 10px; cursor: pointer;">
                <svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" fill="white" viewBox="0 0 24 24" style="margin-right: 8px;">
                    <path d="M12 14c1.66 0 2.99-1.34 2.99-3L15 5c0-1.66-1.34-3-3-3S9 3.34 9 5v6c0 1.66 1.34 3 3 3zm5.3-3c0 3-2.54 5.1-5.3 5.1S6.7 14 6.7 11H5c0 3.41 2.72 6.23 6 6.72V21h2v-3.28c3.28-.48 6-3.3 6-6.72h-1.7z"/>
                </svg>
                Record Audio
            </button>
            
            <button style="width: 100%; background-color: transparent; border: 1px solid #555; border-radius: 4px; color: white; padding: 8px 0; font-size: 14px; display: flex; align-items: center; justify-content: center; cursor: pointer;">
                <svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" fill="white" viewBox="0 0 24 24" style="margin-right: 8px;">
                    <path d="M9.4 10.5l4.77-8.26C13.47 2.09 12.75 2 12 2c-2.4 0-4.6.85-6.32 2.25l3.66 6.35.06-.1zM21.54 9c-.92-2.92-3.15-5.26-6-6.34L11.88 9h9.66zm.26 1h-7.49l.29.5 4.76 8.25C21 16.97 22 14.61 22 12c0-.69-.07-1.35-.2-2zM8.54 12l-3.9-6.75C3.01 7.03 2 9.39 2 12c0 .69.07 1.35.2 2h7.49l-1.15-2zm-6.08 3c.92 2.92 3.15 5.26 6 6.34L12.12 15H2.46zm11.27 0l-3.9 6.76c.7.15 1.42.24 2.17.24 2.4 0 4.6-.85 6.32-2.25l-3.66-6.35-.93 1.6z"/>
                </svg>
                Camera
            </button>
        </div>
        
        <div style="margin-top: 20px; text-align: right;">
            <button style="background-color: transparent; border: none; color: #888; font-size: 12px; cursor: pointer;">
                Safety settings
            </button>
        </div>
        """
        , unsafe_allow_html=True)
        
        # Hidden input tabs for different input types
        input_tabs = st.tabs(["Image Upload", "Audio Recording", "File Upload"])
        
        # Image upload tab
        with input_tabs[0]:
            uploaded_file = st.file_uploader("Upload an image for analysis", type=["jpg", "jpeg", "png"])
            if uploaded_file:
                # Save the uploaded image to session state
                st.session_state.uploaded_image = encode_image(uploaded_file)
                
                # Preview the image
                st.image(uploaded_file, caption="Image ready for analysis", width=300)
        
        # Audio recording tab - Enhanced with WebRTC
        with input_tabs[1]:
            if "audio_data" not in st.session_state:
                st.session_state.audio_data = None
                st.session_state.audio_path = None
                st.session_state.audio_recording_unavailable = False
            
            st.markdown("### Enhanced Audio Recording")
            st.markdown("Record audio with adjustable duration using your microphone")
            
            # Try using WebRTC recorder first
            try:
                # Use the enhanced WebRTC audio recorder
                base64_audio = audio_recorder_ui(
                    key="webrtc_recorder",
                    title="Audio Recording",
                    description="Click start button to begin recording. Click stop when you're done.",
                    durations=[15, 30, 60, 120],
                    show_description=True,
                    show_playback=True
                )
                
                # If audio was recorded, store it in session state
                if base64_audio:
                    st.session_state.audio_data = base64_audio
                    # Path is already stored by the recorder in session state
                    st.session_state.audio_path = st.session_state.get("webrtc_recorder_file_path")
                    
                    # Show success message
                    st.success("Audio recorded successfully!")
                    st.info("You can now send a message to analyze this audio.")
                
            except Exception as e:
                # Fallback to legacy recording if WebRTC fails
                st.error(f"Enhanced audio recording unavailable: {str(e)}")
                st.info("Falling back to basic audio recording...")
                st.session_state.audio_recording_unavailable = True
                
                # Display legacy recording interface
                if not st.session_state.audio_recording_unavailable:
                    st.write("Choose recording duration:")
                    b1, b2 = st.columns(2)
                    
                    # Record 5-second audio
                    if b1.button("Record Audio (5 seconds)", use_container_width=True):
                        try:
                            from utils.audio import record_audio, encode_audio, cleanup_audio_file
                            audio_bytes, temp_file_path = record_audio(duration=5)
                            st.session_state.audio_data = encode_audio(audio_bytes)
                            st.session_state.audio_path = temp_file_path
                            st.success("Audio recorded successfully!")
                            st.audio(temp_file_path)
                        except Exception as e:
                            error_message = str(e)
                            if "microphone is not accessible" in error_message or "Invalid input device" in error_message:
                                st.error("Microphone not available in this environment.")
                                st.info("You can upload an audio file instead or use text input.")
                                st.session_state.audio_recording_unavailable = True
                            else:
                                st.error(f"Failed to record audio: {error_message}")
                    
                    # Record 10-second audio
                    if b2.button("Record Audio (10 seconds)", use_container_width=True):
                        try:
                            from utils.audio import record_audio, encode_audio, cleanup_audio_file
                            audio_bytes, temp_file_path = record_audio(duration=10)
                            st.session_state.audio_data = encode_audio(audio_bytes)
                            st.session_state.audio_path = temp_file_path
                            st.success("Audio recorded successfully!")
                            st.audio(temp_file_path)
                        except Exception as e:
                            error_message = str(e)
                            if "microphone is not accessible" in error_message or "Invalid input device" in error_message:
                                st.error("Microphone not available in this environment.")
                                st.info("You can upload an audio file instead or use text input.")
                                st.session_state.audio_recording_unavailable = True
                            else:
                                st.error(f"Failed to record audio: {error_message}")
                else:
                    # Show alternative options when recording is unavailable
                    st.warning("Audio recording is not available in this environment.")
                    st.info("You can upload a pre-recorded audio file or use text input instead.")
            
            # Separator
            st.markdown("---")
            
            # Upload audio file as alternative
            st.markdown("### Upload Audio File")
            st.markdown("Alternatively, upload a pre-recorded audio file")
            
            uploaded_audio = st.file_uploader("Upload audio file", type=["wav", "mp3", "ogg"], key="audio_upload")
            if uploaded_audio:
                try:
                    # Read the file and encode it
                    audio_bytes = uploaded_audio.getvalue()
                    
                    # Create temporary file
                    temp_file = tempfile.NamedTemporaryFile(suffix="." + uploaded_audio.name.split(".")[-1], delete=False)
                    temp_file_path = temp_file.name
                    temp_file.write(audio_bytes)
                    temp_file.close()
                    
                    # Save to session state
                    from utils.audio import encode_audio
                    st.session_state.audio_data = encode_audio(audio_bytes)
                    st.session_state.audio_path = temp_file_path
                    
                    # Show success and preview
                    st.success("Audio file uploaded successfully!")
                    st.audio(temp_file_path)
                except Exception as e:
                    st.error(f"Failed to process audio file: {str(e)}")
            
            # Button to clear recorded/uploaded audio
            if st.session_state.audio_data and st.button("Clear Audio"):
                if st.session_state.audio_path:
                    try:
                        from utils.audio import cleanup_audio_file
                        cleanup_audio_file(st.session_state.audio_path)
                    except:
                        pass
                st.session_state.audio_data = None
                st.session_state.audio_path = None
                st.rerun()
                
        # File upload tab
        with input_tabs[2]:
            uploaded_doc = st.file_uploader("Upload a document", type=["txt", "pdf", "doc", "docx"], 
                                          help="Upload a document for the AI to analyze")
            if uploaded_doc:
                # Read file content
                if uploaded_doc.type == "text/plain":
                    # Handle text files
                    text_content = uploaded_doc.getvalue().decode("utf-8")
                    st.text_area("Document Content", text_content, height=200)
                    if st.button("Send Document to AI"):
                        # Add document content to user message
                        st.session_state.document_text = f"I'm sharing this document with you: \n\n{text_content}\n\nPlease analyze this content."
                else:
                    # For other file types, just show the filename
                    st.info(f"File '{uploaded_doc.name}' uploaded. Send a message to the AI to analyze it.")
        
        # Simple chat input without emoji functionality
        if user_input := st.chat_input("Message the AI...", key="chat_input_main"):
            # Check if we're in a cooldown period (prevents double messages)
            if st.session_state.message_cooldown:
                st.info("Message already sent! Please wait a moment...")
                return
                
            # Set cooldown to prevent double sending
            st.session_state.message_cooldown = True
                
            # If document was uploaded and button clicked, use document text as message
            if hasattr(st.session_state, 'document_text'):
                user_input = st.session_state.document_text
                # Clear it after use
                delattr(st.session_state, 'document_text')
            
            # Create message object
            user_message = {"role": "user", "content": user_input}
            
            # Add image to message if one is uploaded
            if st.session_state.uploaded_image:
                user_message["image"] = st.session_state.uploaded_image
                
            # Add audio to message if recorded
            if hasattr(st.session_state, 'audio_data') and st.session_state.audio_data:
                user_message["audio"] = st.session_state.audio_data
                # Clear audio data after use
                st.session_state.audio_data = None
                st.session_state.audio_path = None
            
            # Add user message to chat
            st.session_state.messages.append(user_message)
            
            # Get AI response based on selected model
            with st.spinner(f"Thinking... using {st.session_state.current_model}"):
                try:
                    image_data = user_message.get("image")
                    model_name = st.session_state.current_model.lower()
                    
                    # Extract model call sign from selected model if available
                    model_call_sign = None
                    if "(" in st.session_state.current_model and ")" in st.session_state.current_model:
                        model_call_sign = st.session_state.current_model.split("(")[1].split(")")[0]
                    
                    # Gemini models
                    if "gemini" in model_name:
                        # Use extracted call sign or fallback to default
                        gemini_version = model_call_sign if model_call_sign else "gemini-1.5-pro"
                        
                        # Get audio data if available
                        audio_data = user_message.get("audio")
                        
                        ai_response = get_gemini_response(
                            user_input, 
                            st.session_state.messages,
                            image_data=image_data,
                            audio_data=audio_data,
                            temperature=st.session_state.temperature,
                            model_name=gemini_version
                        )
                    
                    # Vertex AI models - direct routing to appropriate API based on model
                    elif "vertex ai" in model_name:
                        if "claude" in model_name.lower():
                            # Use the extracted call sign or default to Claude 3.5
                            claude_model = model_call_sign if model_call_sign else "claude-3-5-sonnet-20241022"
                            ai_response = get_anthropic_response(
                                user_input, 
                                st.session_state.messages,
                                model_name=claude_model
                            )
                        elif "gpt" in model_name.lower():
                            # Use the extracted call sign or default to GPT-4o
                            gpt_model = model_call_sign if model_call_sign else "gpt-4o"
                            ai_response = get_openai_response(
                                user_input, 
                                st.session_state.messages,
                                model_name=gpt_model
                            )
                        else:
                            # For any other Vertex AI models, try the vertex function but with warning
                            ai_response = "Note: This model may not be directly accessible through the current API configuration. " + \
                                        "For best results with third-party models, please select them from their native provider section instead."
                    
                    # OpenAI models
                    elif "openai" in model_name:
                        # Use the extracted call sign or default to gpt-4o
                        openai_model = model_call_sign if model_call_sign else "gpt-4o"
                        ai_response = get_openai_response(
                            user_input, 
                            st.session_state.messages,
                            model_name=openai_model
                        )
                    
                    # Anthropic models
                    elif "anthropic" in model_name:
                        # Use the extracted call sign or default to claude-3-5-sonnet-20241022
                        anthropic_model = model_call_sign if model_call_sign else "claude-3-5-sonnet-20241022"
                        ai_response = get_anthropic_response(
                            user_input, 
                            st.session_state.messages,
                            model_name=anthropic_model
                        )
                    
                    # Perplexity models
                    elif "perplexity" in model_name:
                        # Use the extracted call sign or fallback to default
                        perplexity_model = model_call_sign if model_call_sign else "pplx-70b-online"
                        
                        ai_response = get_perplexity_response(
                            user_input, 
                            st.session_state.messages,
                            temperature=st.session_state.temperature,
                            model_name=perplexity_model
                        )
                    
                    # Fallback for unknown models
                    else:
                        ai_response = "Error: The selected model is not yet implemented."
                        
                    # Add AI response to chat
                    st.session_state.messages.append({"role": "assistant", "content": ai_response})
                    
                    # Clear uploaded image after processing
                    st.session_state.uploaded_image = None
                    
                    # Save conversation to database
                    save_conversation(
                        st.session_state.user,
                        st.session_state.current_model,
                        st.session_state.messages
                    )
                    
                except Exception as e:
                    st.error(f"Error: {str(e)}")
                    st.session_state.messages.append({"role": "assistant", "content": f"Sorry, I encountered an error: {str(e)}"})
                    
                    # Clear uploaded image if there was an error
                    st.session_state.uploaded_image = None
                    
                    # Reset cooldown to allow user to try again
                    st.session_state.message_cooldown = False
            
            # Reset cooldown for future messages
            st.session_state.message_cooldown = False
            
            # Force a rerun to show the new messages and reset UI state
            st.rerun()
    
    # This section is now merged into the sidebar, so we no longer use it
    if False: # Keeping the code for reference but never executing it
        # Right sidebar with enhanced Google AI Studio style settings
        with st.container():
            # Display user profile at the top of the sidebar if authenticated
            if st.session_state.is_authenticated and st.session_state.user:
                user_info = st.session_state.user
                user_name = user_info.get("name", "User")
                user_email = user_info.get("email", "")
                user_picture = user_info.get("picture", "")
                
                # User profile section with picture
                st.markdown(f"""
                <div style="padding: 15px 0; border-bottom: 1px solid #333; margin-bottom: 15px; display: flex; align-items: center;">
                    <div style="border-radius: 50%; overflow: hidden; width: 50px; height: 50px; margin-right: 10px;">
                        <img src="{user_picture}" style="width: 100%; height: 100%; object-fit: cover;" onerror="this.src='https://ui-avatars.com/api/?name={user_name}&background=random'">
                    </div>
                    <div>
                        <div style="font-weight: bold; color: white;">{user_name}</div>
                        <div style="font-size: 0.8rem; color: #aaa;">{user_email}</div>
                        <div style="font-size: 0.7rem; color: #4285f4; margin-top: 2px;">
                            {"Administrator" if is_admin() else "User"}
                        </div>
                    </div>
                </div>
                """, unsafe_allow_html=True)
                
                # Logout button
                if st.button("Logout", key="logout_button"):
                    logout_user()
                    st.rerun()
            
            st.markdown("""
            <div style="padding: 10px 0; border-bottom: 1px solid #333; margin-bottom: 15px;">
                <h3 style="color: #4285f4; font-size: 1.3rem;">AI Studio Settings</h3>
            </div>
            """, unsafe_allow_html=True)
            
            # Voice command functions
            def toggle_voice_commands(enable):
                """Toggle voice commands on/off"""
                if enable:
                    if not st.session_state.voice_processor:
                        try:
                            # Import voice command processor
                            from utils.voice_commands import VoiceCommandProcessor
                            
                            # Initialize processor with command callbacks
                            processor = VoiceCommandProcessor()
                            
                            # Register command callbacks
                            processor.register_callback("new_chat", lambda: st.session_state.update(messages=[]))
                            processor.register_callback("select_model_gemini", lambda: st.session_state.update(current_model="Gemini"))
                            processor.register_callback("select_model_claude", lambda: st.session_state.update(current_model="Anthropic (claude-3-5-sonnet-20241022)"))
                            processor.register_callback("select_model_gpt", lambda: st.session_state.update(current_model="OpenAI (gpt-4o)"))
                            processor.register_callback("increase_temperature", lambda: st.session_state.update(temperature=min(1.0, st.session_state.temperature + 0.1)))
                            processor.register_callback("decrease_temperature", lambda: st.session_state.update(temperature=max(0.0, st.session_state.temperature - 0.1)))
                            
                            # Add send message command
                            def send_dictated_message(text=None):
                                if text:
                                    # Create a new user message
                                    st.session_state.messages.append({"role": "user", "content": text})
                                    st.rerun()
                            
                            processor.register_callback("send_message", send_dictated_message)
                            
                            # Save the processor to session state
                            st.session_state.voice_processor = processor
                            
                            # Start listening
                            processor.start_listening()
                            st.session_state.is_listening = True
                        except Exception as e:
                            st.error(f"Failed to initialize voice commands: {str(e)}")
                            st.session_state.voice_commands_active = False
                            return
                    else:
                        # Restart the existing processor
                        st.session_state.voice_processor.start_listening()
                        st.session_state.is_listening = True
                else:
                    # Stop listening if processor exists
                    if st.session_state.voice_processor:
                        st.session_state.voice_processor.stop_listening()
                        st.session_state.is_listening = False
                
                # Update the active state
                st.session_state.voice_commands_active = enable
            
            # Theme selection
            st.markdown("""
            <div style="margin-top: 10px; border-top: 1px solid #333; padding-top: 15px;">
                <p style="font-weight: 500; margin-bottom: 5px;">Appearance</p>
            </div>
            """, unsafe_allow_html=True)
            
            selected_theme = st.selectbox(
                "Theme",
                options=list(THEMES.keys()),
                index=list(THEMES.keys()).index(st.session_state.current_theme),
                help="Select a color theme for the app"
            )
            
            # Apply theme if changed
            if selected_theme != st.session_state.current_theme:
                st.session_state.current_theme = selected_theme
                st.rerun()
            
            # Text-to-Speech settings section
            st.markdown("""
            <div style="margin-top: 10px; border-top: 1px solid #333; padding-top: 15px;">
                <p style="font-weight: 500; margin-bottom: 5px;">Speech</p>
            </div>
            """, unsafe_allow_html=True)
            
            # Initialize TTS settings in session state if not present
            if "tts_settings" not in st.session_state:
                st.session_state.tts_settings = {}
            
            # Add the TTS controls to the sidebar
            tts_settings = render_tts_controls()
            st.session_state.tts_settings = tts_settings
                
            # Model selection with specific model variants, icons, and call signs
            st.markdown("""
            <div style="margin-top: 10px; border-top: 1px solid #333; padding-top: 15px;">
                <p style="font-weight: 500; margin-bottom: 5px;">Model</p>
            </div>
            """, unsafe_allow_html=True)
            
            # Display model provider icons (without using nested columns)
            st.markdown("""
            <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 10px;">
                <div style="text-align: center;"><img src="data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyI+PHBhdGggZD0iTTIyLjA5IDE2LjEzTDIxLjEyIDE2LjIxTDIwLjU5IDE3LjA3QzE5Ljg0IDE4LjMzIDE4Ljc2IDE5LjMyIDE3LjQ3IDIwTDEyIDE2Ljg4TDYuNTMgMjBDNS4yNSAxOS4zNCA0LjE2IDE4LjM1IDMuNDEgMTcuMDlMMi44OCAxNi4yMkwxLjkxIDE2LjE0QzAuOTQgMTYuMDYgMCAxNS4zMiAwIDE0LjVDMCAxMy42OCAwLjk0IDEyLjkzIDEuOTEgMTIuODZMMi44OCAxMi43OEwzLjQxIDExLjkzQzQuMTYgMTAuNjcgNS4yNSA5LjY4IDYuNTMgOUwxMiAxMi4xMkwxNy40NyA5QzE4Ljc2IDkuNjggMTkuODQgMTAuNjcgMjAuNTkgMTEuOTNMMjEuMTIgMTIuNzhMMjIuMDkgMTIuODZDMjMuMDYgMTIuOTMgMjQgMTMuNjkgMjQgMTQuNUMyNCAxNS4zMiAyMy4wNiAxNi4wNiAyMi4wOSAxNi4xM00xMS45OSA1Ljg0TDcuNSAzLjA0QzYuNzggMi45NyA2LjA2IDMgNS4zNCAzLjA3TDQuNjEgMy4xNUwzLjkyIDMuNTRDMy4xNSAzLjk5IDIuNTMgNC42NyAyLjEyIDUuNUwyLjEgNS41QzEuODUgNi4wNiAxLjcyIDYuNjkgMS43MSA3LjM1TDEuNzYgOC4xOEwxLjk3IDguODRDMi4yMiA5LjUgMi41OSAxMC4wNiAzLjA5IDEwLjVMNy41IDcuNjlMMTIgNEwxNi41IDcuNjlMMjAuOTEgMTAuNUMyMS40MiAxMC4wNiAyMS43OCA5LjUgMjIuMDQgOC44NEwyMi4yNCA4LjE4TDIyLjI5IDcuMzVDMjIuMjcgNi42OCAyMi4xNSA2LjA2IDIxLjg5IDUuNUMyMS40OSA0LjY3IDIwLjg2IDMuOTkgMjAuMDkgMy41NEwxOS40IDMuMTVMMTguNjcgMy4wNkMxNy45NCAzIDE3LjIyIDIuOTcgMTYuNSAzLjA0TDExLjk5IDUuODQiIGZpbGw9IiM0Mjg1RjQiLz48L3N2Zz4=" width="24" alt="Gemini"><br><small>Gemini</small></div>
                <div style="text-align: center;"><img src="data:image/svg+xml;base64,<svg width="24" height="24" xmlns="http://www.w3.org/2000/svg"><path d="M22.56 17.44C21.15 15.45 18.18 12.83 18.18 12.83C19.06 11.24 20.08 8.7 20.11 7.04C20.15 5.27 19.46 4.12 18.32 3.46C17.05 2.73 15.64 3.05 14.79 3.48C13.94 3.91 13.07 4.62 12.73 6.15C12.5 7.15 12.65 8.08 12.78 8.74C12.86 9.12 13.02 9.57 13.18 10.01C13.42 10.69 13.89 11.69 13.41 12.61C13.14 13.13 12.88 13.38 12.59 13.47C12.42 13.52 12.4 13.49 12.29 13.44C12.26 13.43 12.22 13.41 12.15 13.38C12.06 13.34 11.95 13.28 11.84 13.18C11.62 13.01 11.3 12.71 11.11 12.23C10.75 11.28 10.7 10.16 10.95 9.14C11.03 8.77 11.19 8.38 11.35 7.99C11.47 7.68 11.69 7.43 11.83 7.11C12.81 5.11 12.42 1.75 9.78 0.79C8.68 0.37 7.58 0.49 6.57 1.02C5.66 1.5 4.9 2.34 4.5 3.62C4.2 4.54 4.18 5.45 4.35 6.37C4.53 7.39 4.86 8.37 5.2 9.2C5.37 9.61 5.65 10.27 5.71 10.53C5.73 10.64 5.76 10.72 5.54 11.02C5.32 11.32 5.18 11.32 5.06 11.28C4.75 11.19 4.36 10.83 4.14 10.59C3.79 10.2 3.44 9.67 3.26 9.24C3.12 8.89 3.03 8.52 2.96 8.14C2.8 7.37 2.84 6.6 3.09 5.82C3.53 4.47 4.83 3.54 6.02 3.15C7.56 2.63 9.41 2.89 10.73 3.85C12.42 5.06 13.41 7.4 13.39 9.73C13.39 10.19 13.33 10.42 13.33 10.73C13.33 10.94 13.52 11.12 13.65 11.17C13.8 11.23 13.94 11.17 14.06 11.06C14.25 10.89 14.4 10.61 14.51 10.34C15.2 8.42 14.99 6.01 13.7 4.63C11.96 2.76 8.91 2.85 7.33 4.8C6.85 5.4 6.57 6.12 6.45 6.93C6.32 7.8 6.44 8.65 6.61 9.27C6.72 9.65 6.95 10.21 7.04 10.59C7.06 10.69 7.08 10.77 7.08 10.82C7.09 10.92 7.12 10.98 7.1 11.03C7.02 11.18 6.89 11.24 6.76 11.29C6.57 11.38 6.39 11.33 6.23 11.27C6.1 11.22 5.98 11.15 5.88 11.09C5.65 10.96 5.41 10.74 5.21 10.47C4.94 10.11 4.69 9.64 4.57 9.1C4.07 7.36 4.31 5.24 5.8 3.87C7.44 2.36 10.15 2.41 11.75 3.96C12.8 5.01 13.28 6.47 13.25 7.96C13.22 9.88 12.29 11.85 11.6 12.98C10.82 14.26 9.76 15.37 8.72 16.41C7.94 17.18 6.74 18.23 6.18 18.83C5.64 19.39 5.29 19.94 5.14 20.37C5.03 20.67 5.04 20.95 5.07 21.15C5.19 22.05 5.74 22.33 6.2 22.48C6.82 22.68 7.55 22.64 8.14 22.47C9.06 22.21 9.88 21.68 10.57 21.14C11.71 20.26 12.58 19.1 13.67 18.06C16.06 15.78 18.88 13.63 21.23 11.29C21.6 10.92 22.08 10.44 22.48 10.04C22.67 9.85 22.94 9.56 23.09 9.41C23.19 9.29 23.38 9.08 23.48 8.75C23.65 8.17 23.51 7.68 23.41 7.47C23.29 7.19 23.13 7.05 22.89 6.95C22.53 6.81 22.19 6.83 21.98 6.86C21.69 6.91 21.4 7.01 21.14 7.1C20.89 7.19 20.64 7.31 20.4 7.45C20.09 7.63 19.79 7.87 19.49 8.11C19.23 8.3 18.97 8.55 18.76 8.75C18.57 8.94 18.34 9.2 18.18 9.36C17.94 9.61 17.81 9.74 17.64 9.91C17.05 10.5 16.46 11.09 15.89 11.69C15.88 11.69 15.87 11.7 15.86 11.71L13.91 13.81C13.5 14.26 13.12 14.74 12.76 15.21C12.61 15.42 12.35 15.8 12.19 15.99C12.02 16.19 11.88 16.41 11.75 16.65C11.53 17.06 11.5 17.4 11.65 17.74C11.82 18.13 12.21 18.35 12.58 18.43C13.21 18.57 13.84 18.42 14.51 18.25C14.93 18.15 15.29 17.97 15.59 17.8C15.8 17.68 16.02 17.53 16.18 17.41C16.61 17.1 17.01 16.76 17.44 16.39C19.75 14.4 21.92 12.3 24 19.16C24 19.16 23.72 19.65 23.29 20.29C22.6 21.29 21.7 22.4 20.7 23C19.74 23.56 18.4 23.83 17.72 23.93C16.97 24.03 15.53 24 3.99 23.97C3.75 23.96 3.45 23.95 3.17 23.91C2.3 23.77 0.99 23.18 1 21.94C1.01 20.72 2.16 20.02 3.11 19.61C3.88 19.27 4.78 19.25 5.46 19.45C6.01 19.61 6.16 19.81 6.44 20.09C6.75 20.39 6.84 20.7 6.8 21.02C6.74 21.48 6.32 21.83 5.97 21.99C5.56 22.18 4.98 22.24 4.56 22.08C4.14 21.92 4.45 21.51 4.03 21.31C3.86 21.23 3.55 21.29 3.4 21.37C3.22 21.47 3.08 21.65 3.1 21.86C3.14 22.3 3.71 22.53 4.07 22.6C4.92 22.78 5.86 22.63 6.64 22.45C7.09 22.34 7.54 22.17 7.92 21.91C8.29 21.65 8.61 21.3 8.77 20.9C8.91 20.52 8.91 20.13 8.84 19.75C8.72 19.11 8.29 18.56 7.87 18.16C6.87 17.2 5.7 16.98 4.44 17.16C3.43 17.3 2.54 17.71 1.79 18.31C1.03 18.92 0.38 19.81 0.2 20.85C0.07 21.63 0.27 22.36 0.68 22.96C1.13 23.62 1.86 24.04 2.61 24.27C3.33 24.49 4.1 24.51 4.88 24.49C5.41 24.48 5.93 24.4 16.52 24.5C18.36 24.52 19.37 24.39 20.29 24.25C21.33 24.08 22.36 23.76 23.17 23.31C24.04 22.83 24.75 22.16 25.29 21.49C25.8 20.86 26.16 20.19 26.36 19.62C26.73 18.6 26.62 17.84 26.3 17.31C25.96 16.76 25.39 16.49 24.99 16.35C24.03 16.04 22.93 16.07 22.06 16.47C21.21 16.86 20.67 17.64 20.63 18.57C20.6 19.33 20.92 20.06 21.46 20.46C21.98 20.86 22.73 21.02 23.4 20.87C23.76 20.79 24.08 20.61 24.3 20.3C24.48 20.03 24.57 19.69 24.54 19.34C24.49 18.84 24.11 18.44 23.69 18.18C23.26 17.93 22.75 17.8 22.23 17.79C21.16 17.79 20.26 18.38 20 19.39C19.86 20.01 20.05 20.62 20.37 21.1C20.7 21.58 21.17 21.92 21.74 22.14C22.3 22.35 22.93 22.45 23.56 22.42C24.18 22.39 24.81 22.22 25.34 21.92C25.86 21.64 26.29 21.24 26.59 20.74C26.89 20.23 27 19.64 26.96 19C26.86 17.66 25.96 16.57 24.77 15.94C23.56 15.29 22.07 15.2 20.86 15.68C19.64 16.16 18.79 17.19 18.55 18.43C18.44 18.98 18.5 19.53 18.67 20.05C18.9 20.7 19.31 21.25 19.86 21.67C20.4 22.09 21.09 22.36 21.81 22.47C22.53 22.59 23.29 22.53 23.99 22.29C24.76 22.03 25.42 21.49 24.21 21.29C23.77 21.22 23.05 21.27 23.07 20.68C23.09 20.21 23.53 20.03 23.95 20.06C24.49 20.1 25.01 20.4 25.19 20.92C25.38 21.46 25.12 22.06 24.71 22.4C24.2 22.83 23.49 23.04 22.81 23.02C22.13 22.99 21.48 22.75 20.97 22.32C20.45 21.88 20.1 21.24 19.98 20.56C19.88 19.94 19.96 19.28 20.23 18.71C20.78 17.55 22.28 16.94 23.6 17.37C24.36 17.61 24.96 18.12 25.3 18.8C25.5 19.22 25.57 19.69 25.51 20.17C25.44 20.7 25.18 21.19 24.77 21.57C24.37 21.95 23.83 22.2 23.26 22.3C22.72 22.4 22.12 22.33 21.61 22.14C21.1 21.95 20.67 21.64 20.35 21.24C20.02 20.84 19.82 20.34 19.76 19.83C19.65 19.04 19.85 18.18 20.34 17.56C21.32 16.29 23.24 16"40e18.24C24.37 18.52 24.86 19.19 25.05 19.75C25.25 20.33 25.15 20.97 24.85 21.52C24.54 22.08 24.06 22.53 23.47 22.8C22.89 23.07 22.21 23.14 21.57 23.03C20.93 22.91 20.33 22.62 19.86 22.19C19.39 21.76 19.05 21.19 18.88 20.57C18.71 19.94 18.73 19.25 18.93 18.64C19.32 17.44 20.36 16.55 21.57 16.16C22.77 15.76 24.16 15.86 25.26 16.42C26.36 16.99 27.2 18.01 27.39 19.19C27.47 19.77 27.41 20.36 27.19 20.91C26.97 21.45 26.6 21.93 26.13 22.31C25.65 22.68 25.05 22.95 24.41 23.09C23.76 23.22 23.08 23.21 22.43 23.07C21.77 22.92 21.15 22.64 20.64 22.23C20.13 21.82 19.74 21.28 19.51 20.68C19.28 20.08 19.23 19.42 19.36 18.8C19.61 17.57 20.46 16.53 21.58 15.97C23.02 15.24 24.83 15.31 26.2 16.18C26.93 16.62 27.49 17.26 27.83 18.03C28.14 18.75 28.22 19.56 28.02 20.34C27.84 21.1 27.37 21.8 26.76 22.3C26.15 22.8 25.41 24.1 24.58 23.19C23.73 23.27 22.85 23.13 22.07 22.79C21.28 22.44 20.62 21.89 20.2 21.2C19.78 20.5 19.63 19.7 19.75 18.91C19.88 18.12 20.26 17.39 20.86 16.82C22.04 15.71 23.81 15.48 25.22 16.08C25.93 16.38 26.54 16.88 26.98 17.52C27.43 18.16 27.69 18.92 27.69 19.7C27.69 20.77 27.2 21.8 26.43 22.52C25.66 23.23 24.64 23.61 23.59 23.64C22.55 23.66 21.51 23.34 20.75 22.72C20.37 22.41 20.05 22.02 19.83 21.59C19.6 21.16 19.47 20.69 19.42 20.2C19.3 19.23 19.59 18.24 20.2 17.51C20.81 16.77 21.71 16.31 22.68 16.23C23.64 16.16 24.64 16.44 25.4 17.02C26.17 17.61 26.67 18.48 26.75 19.41C26.83 20.34 26.48 21.27 25.85 21.97C25.22 22.67 24.32 23.09 23.38 23.15C22.45 23.21 21.5 22.91 20.8 22.32C20.09 21.72 19.65 20.84 19.58 19.9C19.55 19.44 19.62 18.97 19.79 18.54C19.95 18.11 20.21 17.73 20.54 17.42C21.21 16.8 22.15 16.51 23.04 16.62C23.94 16.74 24.76 17.25 25.22 17.99C25.69 18.73 25.79 19.66 25.51 20.49C25.24 21.32 24.61 22.01 23.8 22.39C22.98 22.77 22.02 22.83 21.15 22.56C20.28 22.29 19.55 21.71 19.16 20.93C18.72 20.18 18.29 18.76"19.84 17.55C19.93 17.53 19.99 17.44 20.07 17.44C20.47 17.41 21.02 17.55 21.39 17.8C21.48 17.86 21.59 17.95 21.7 18.05C21.81 18.16 21.91 18.28 22.01 18.42C22.36 18.85 22.51 19.42 22.42 19.98C22.34 19.93 22.32 19.86 22.27 19.8C22.21 19.7 22.15 19.6 22.07 19.5C22.06 19.55 21.88 19.7 21.86 19.72L21.23 20.14L20.55 20.32C20.37 20.39 20.18 20.42 20 20.41C19.46 20.38 19.01 19.97 18.86 19.47C18.77 19.19 18.78 18.88 18.88 18.6C19 18.3 19.19 18.04 19.43 17.85C20.07 17.32 21.05 17.17 21.87 17.37C22.03 17.42 22.2 17.51 22.34 17.63C22.79 17.99 23.04 18.55 23.02 19.15C23 19.67 22.76 20.17 22.36 20.53C21.51 21.28 20.08 21.34 19.15 20.71C18.23 20.08 17.94 18.91 18.33 17.97C18.64 17.21 19.34 16.69 20.14 16.55C20.95 16.42 21.83 16.66 22.42 17.22C23.01 17.77 23.29 18.6 23.17 19.42C23.06 20.23 22.56 20.96 21.85 21.4C21.13 21.85 20.21 21.97 19.39 21.74C18.57 21.51 17.92 20.96 17.57 20.23C17.21 19.5 17.19 18.62 17.51 17.87C17.82 17.12 18.48 16.54 19.27 16.31C20.07 16.08 20.96 16.22 21.66 16.66C22.36 17.11 22.81 17.85 22.91 18.66C23.01 19.48 22.75 20.31 22.19 20.92C21.63 21.54 20.8 21.9 20.01 21.95C19.21 22 18.41 21.73 17.83 21.2C17.24 20.67 16.92 19.89 16.96 19.1C17 18.3 17.4 17.57 18.04 17.13C18.68 16.69 19.53 16.55 20.3 16.74C21.06 16.94 21.71 17.46 22.06 18.16C22.4 18.86 22.43 19.71 22.12 20.44C21.81 21.16 21.19 21.74 20.44 22.02C19.69 22.29 18.83 22.27 18.09 21.93C17.35 21.6 16.83 20.96 16.65 20.21C16.36 18.99 17.07 17.71 18.22 17.15C19.22 16.66 20.45 16.84 21.28 17.56C22.12 18.28 22.43 19.5 22.05 20.57C21.66 21.63 20.69 22.41 19.55 22.64C19.06 22.74 18.54 22.72 18.06 22.6C17.58 22.48 17.14 22.25 16.78 21.95C16.06 21.34 15.64 20.41 15.68 19.45C15.71 18.49 16.19 17.59 16.95 17.02C17.7 16.45 18.71 16.22 19.62 16.42C20.54 16.61 21.32 17.21 21.74 18.02C22.16 18.83 22.18 19.82 21.81 20.65C21.43 21.48 20.69 22.13 19.85 22.37C19 22.61 18.08 22.43 17.35 21.89C16.62 21.34 16.2 20.46 16.24 19.54C16.28 18.62 16.77 17.77 17.52 17.28C18.27 16.79 19.26 16.66 20.14 16.92C21.03 17.18 21.75 17.82 22.09 18.67C22.42 19.52 22.35 20.5 21.9 21.28C21.45 22.06 20.65 22.61 19.74 22.77C18.84 22.92 17.89 22.67 17.17 22.08C16.44 21.49 16 20.6 15.98 19.66C15.96 18.71 16.33 17.8 17.02 17.17C17.71 16.54 18.66 16.24 19.59 16.37C20.52 16.51 21.35 17.06 21.82 17.83C22.3 18.6 22.39 19.58 22.07 20.44C21.75 21.3 21.05 22 20.19 22.35C19.34 22.7 18.35 22.68 17.51 22.28C16.67 21.89 16.06 21.14 15.84 20.25C15.43 18.45 16.55 16.62 18.34 16.12C19.23 15.87 20.21 16.04 20.97 16.58C21.73 17.13 22.21 17.98 22.26 18.91C22.32 19.84 21.96 20.76 21.28 21.39C20.61 22.02 19.66 22.31 18.77 22.18C17.87 22.05 17.09 21.51 16.67 20.73C16.25 19.95 16.23 19.02 16.61 18.21C16.99 17.41 17.74 16.84 18.61 16.66C19.48 16.48 20.41 16.7 21.09 17.26C21.77 17.81 22.17 18.67 22.19 19.58C22.21 20.49 21.83 21.36 21.17 21.93C20.51 22.5 19.6 22.75 18.71 22.61C17.83 22.47 17.06 21.96 16.64 21.23C16.21 20.5 16.14 19.62 16.45 18.83C16.76 18.04 17.43 17.41 18.24 17.12C19.05 16.83 19.97 16.91 20.71 17.33C21.45 17.75 21.97 18.48 22.14 19.32C22.31 20.15 22.11 21.05 21.61 21.72C21.1 22.39 20.3 22.8 19.45 22.84C18.6 22.89 17.77 22.57 17.16 22C16.54 21.42 16.22 20.63 16.22 19.78C16.22 18.93 16.55 18.13 17.17 17.56C17.79 16.99 18.62 16.68 19.45 16.73C20.28 16.79 21.06 17.19 16.57 17.83C22.09 18.48 22.29 19.36 22.12 20.18C21.96 20.99 21.43 21.7 20.69 22.11C19.95 22.51 19.04 22.57 22.23 22.27C17.41 21.97 16.81 21.3 16.6 19.47C16.39 19.04 16.42 18.57 16.55 18.14C16.69 17.71 16.94 17.33 17.26 17.03C17.9 16.43 18.78 16.13 19.66 16.24C20.53 16.35 21.34 16.87 21.76 17.63C22.18 18.38 22.2 19.3 21.83 20.07C21.45 20.84 20.71 21.41 19.84 21.6C18.98 21.78 18.04 21.56 17.36 20.99C16.67 20.43 16.28 19.57 26.35 18.7C16.41 17.84 16.9 17.22 17.83 17.65C22.4.1 22.47 18.77 22.5 19.71C22.53 20.16 22.47 20.62 22.33 21.05C22.2 21.48 21.98 21.86 21.69 18.17C21.09 22.81 20.21 23.13 29.28 22.99C18.36 22.86 17.46 22.45 16.85 21.72C16.24 21 15.97 20.04 16.1 19.1C16.23 18.17 16.74 17.31 17.52 16.76C18.29 16.21 19.32 15.93 20.27 16.15C21.22 16.37 22.07 17.09 22.39 18C22.74 18.99 22.51 20.11 21.82 20.86C21.12 21.61 20.04 21.92 19.04 19.75C18.04 16.57 17.37 16.25 20.84 17.99C16.33 17.42 16.09 17.17 16.0 17.04C15.54 16.92 15.16 16.92 14.84 17.04C14.52 17.17 14.26 17.42 14.14 17.75C14.03 18.08 14.06 18.46 14.24 18.77C14.43 19.08 14.74 19.31 15.12 19.41C15.7 19.58 16.4 19.41 16.85 12.96C17.3 12.51 17.48 11.85 17.35 11.27C17.21 10.69 16.78 10.24 16.18 10.1C15.59 9.96 14.95 10.14 14.51 10.59C14.07 11.03 13.89 11.68 14.02 12.26C14.15 12.84 14.59 13.29 15.18 19.44C15.78 19.58 16.42 19.4 16.86 18.96C17.3 18.53 17.48 17.88 17.35 17.3C17.22 16.72 16.78 16.27 16.19 16.13C15.36 16.93 14.83 13.99 14.64 14.79C14.44 15.59 14.7 16.46 15.31 17.07C15.91 17.67 16.79 17.94 17.59 17.75C18.39 17.55 19.03 16.95 19.21 16.17C19.47 14.98 18.82 13.72 17.67 13.17C16.53 12.61 15.1 12.84 14.25 13.72C13.39 14.59 13.21 16.06 13.85 17.2C14.3 17.97 15.14 18.51 16.07 18.61C17 18.71 17.95 18.37 18.65 17.71C19.07 17.31 19.36 16.78 19.46 16.2C19.63 15.29 19.42 14 8.93 14.92C18.43 15.85 17.69 16.98 16.83 17.82C15.98 18.67 14.79 19.11 13.63 18.99C12.46 18.88 11.4 18.21 10.77 17.22C9.56 15.49 9.79 13.02 11.34 11.57C12.89 10.12 15.32 10.2 16.77 11.75C17.53 12.6 17.91 13.73 17.87 14.86C17.82 15.99"17.36 17.09 16.59 17.9C15.82 18.71 13.28 19.24 35.75 19.22C11.82 19.19 10.63 18.62 9.84 17.77C9.05 16.91 8.68 15.76 8.83 14.61C8.99 13.47 9.63 12.45 10.58 11.81C12.48 10.54 15.02 11.09 16.3 12.98C17.57 14.88 17.07 17.44 15.24 18.73C14.34 19.39 13.21 19.66 12.14 19.47C11.07 19.27 10.14 18.64 9.56 17.74C3.38 14.95 9.07 12.08 10.49 10.58C11.9 9.08 14.02 8.62 15.87 9.38C17.72 10.14 18.95 11.96 18.98 14Dz" fill="#AF2124"/></svg>" width="24" alt="OpenAI"><br><small>OpenAI</small></div>
                <div style="text-align: center;"><img src="data:image/svg+xml;base64,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" width="24" alt="Claude"><br><small>Claude</small></div>
                <div style="text-align: center;"><img src="data:image/svg+xml;base64,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" width="24" alt="Perplexity"><br><small>Perplexity</small></div>
            </div>
            """
            , unsafe_allow_html=True)
            
            model_options = [
                # Gemini models with their specific versions and exact call signs
                "Gemini - 2.5 Pro (gemini-2.5-pro-preview-03-25)",
                "Gemini - 2.0 Flash (gemini-2.0-flash-001)",
                "Gemini - 2.0 Flash-Lite (gemini-2.0-flash-lite-001)",
                "Gemini - 1.5 Pro (gemini-1.5-pro-001)",
                "Gemini - 1.5 Flash (gemini-1.5-flash-001)",
                "Gemini - 1.5 Flash-8B (gemini-1.5-flash-8b-001)",
                
                # Gemini Live API models
                "Gemini - 2.0 Flash Live (gemini-2.0-flash-live-preview-04-09)",
                
                # Vertex AI models
                "Vertex AI - Claude 3.5 Sonnet (claude-3-5-sonnet-20241022)",
                "Vertex AI - Claude 3 Opus (claude-3-opus-20240229)",
                "Vertex AI - GPT-4o (gpt-4o)",
                
                # Direct API models
                "OpenAI - GPT-4o (gpt-4o)",
                "Anthropic - Claude 3.5 Sonnet (claude-3-5-sonnet-20241022)",
                "Anthropic - Claude 3 Opus (claude-3-opus-20240229)",
                
                # Perplexity models
                "Perplexity - 70B Online (pplx-70b-online)",
                "Perplexity - 7B Online (pplx-7b-online)",
                "Perplexity - 70B Chat (pplx-70b-chat)"
            ]
            
            # Find the closest match in model_options for current_model
            current_index = 0
            if st.session_state.current_model:
                for i, option in enumerate(model_options):
                    if st.session_state.current_model in option:
                        current_index = i
                        break
            
            selected_model = st.selectbox(
                "Select AI model",
                options=model_options,
                index=current_index,
                label_visibility="collapsed",
                key="model_selector"
            )
            
            if selected_model != st.session_state.current_model:
                # Model changed - attempt to load most recent chat for this model
                chat_id, messages = get_most_recent_chat(st.session_state.user, selected_model)
                
                # Update session state with new model
                st.session_state.current_model = selected_model
                
                # Update chat_id in session state
                st.session_state.chat_id = chat_id
                
                # Update messages if found for this model
                if messages:
                    st.session_state.messages = messages
                    st.info(f"Loaded most recent {selected_model} chat")
                else:
                    # If no chat exists for this model, start a new one
                    st.session_state.messages = []
                    st.info(f"Started a new {selected_model} chat")
                
                # Clear uploaded image when switching models
                st.session_state.uploaded_image = None
                
                # Force a rerun to refresh the chat
                st.rerun()
            
            # Model settings based on selection with enhanced UI
            st.markdown("""
            <div style="margin-top: 20px; padding-top: 15px; border-top: 1px solid #333;">
                <p style="font-weight: 500; margin-bottom: 5px; color: #4285f4;">Response Settings</p>
            </div>
            """, unsafe_allow_html=True)
            
            # Show temperature control for all models except Claude/Anthropic which have fixed settings
            if "anthropic" not in st.session_state.current_model.lower():
                st.write("Temperature")
                
                # Create two columns for min/max labels
                temp_label_cols = st.columns([1, 1])
                with temp_label_cols[0]:
                    st.markdown("<p style='color: #888; font-size: 0.8rem; margin: 0;'>Precise</p>", unsafe_allow_html=True)
                with temp_label_cols[1]:
                    st.markdown("<p style='color: #888; font-size: 0.8rem; text-align: right; margin: 0;'>Creative</p>", unsafe_allow_html=True)
                
                temperature = st.slider(
                    "Select temperature", 
                    0.0, 1.0, 
                    st.session_state.temperature, 
                    0.1, 
                    label_visibility="collapsed"
                )
                if temperature != st.session_state.temperature:
                    st.session_state.temperature = temperature
                
                # Additional model options
                st.write("Output tokens")
                max_tokens = st.slider("Max tokens", 100, 1500, 800, 100, label_visibility="collapsed")
                
            # Add New Chat button
            st.markdown("""
            <div style="margin-top: 30px; padding-top: 15px; border-top: 1px solid #333; margin-bottom: 10px;">
                <p style="font-weight: 500; margin-bottom: 5px; color: #4285f4;">Chat Actions</p>
            </div>
            """, unsafe_allow_html=True)
            
            if st.button("New Chat", use_container_width=True):
                # Clear messages but keep other settings
                st.session_state.messages = []
                st.session_state.chat_id = None
                # Visual confirmation
                st.success("Started a new chat!")
                st.rerun()
            
            # Features with toggle buttons styled like Google AI Studio
            st.subheader("Features")
            multi_turn = st.toggle("Multi-turn conversation", value=True)
            
            # Add visual examples of capabilities like in Google AI Studio
            st.subheader("Capabilities")
            capabilities_cols = st.columns(3)
            with capabilities_cols[0]:
                st.markdown("‚å®Ô∏è Text & Code")
            with capabilities_cols[1]:
                st.markdown("üñºÔ∏è Images")
            with capabilities_cols[2]:
                st.markdown("üîä Audio")
            
            # Current user info
            st.subheader("User")
            st.write(f"Current user: {st.session_state.user}")
            
            # Voice Command UI
            st.markdown("""
            <div style="margin-top: 30px; border-top: 1px solid #333; padding-top: 15px;">
            </div>
            """, unsafe_allow_html=True)
            
            # Render voice command UI with toggle function
            render_voice_command_ui(
                voice_active=st.session_state.voice_commands_active,
                toggle_callback=toggle_voice_commands,
                is_listening=st.session_state.is_listening
            )
            
            # Render floating voice button if active
            if st.session_state.voice_commands_active:
                render_floating_voice_button(st.session_state.is_listening)
            
            # Logout button
            if st.button("Logout", use_container_width=True):
                # Clean up voice processor before logout
                if st.session_state.voice_processor:
                    st.session_state.voice_processor.stop_listening()
                    st.session_state.voice_processor = None
                    st.session_state.is_listening = False
                logout_user()
                st.rerun()
            
            # Load previous conversations with a better filing system
            st.subheader("Chat Library")
            
            # Add search box for filtering conversations
            search_term = st.text_input("Search chats by model or content", key="chat_search")
            
            # Get all conversations
            previous_conversations = load_conversations(st.session_state.user)
            
            if previous_conversations:
                # Group conversations by model
                model_groups = {}
                for convo in previous_conversations:
                    model = convo.get("model", "Unknown model")
                    if model not in model_groups:
                        model_groups[model] = []
                    model_groups[model].append(convo)
                
                # Display groups in expandable sections
                for model, convos in model_groups.items():
                    # Skip if search term is provided and not found in model name
                    if search_term and search_term.lower() not in model.lower():
                        # Try to search in conversation content
                        found_content = False
                        for convo in convos:
                            messages = convo.get("messages", [])
                            for msg in messages:
                                if search_term.lower() in msg.get("content", "").lower():
                                    found_content = True
                                    break
                            if found_content:
                                break
                        if not found_content:
                            continue
                    
                    with st.expander(f"{model} ({len(convos)} chats)", expanded=False):
                        # Sort conversations by date
                        sorted_convos = sorted(
                            convos, 
                            key=lambda x: x.get("last_updated", x.get("timestamp", "1900-01-01")),
                            reverse=True
                        )
                        
                        for idx, convo in enumerate(sorted_convos):
                            timestamp = convo.get("last_updated", convo.get("timestamp", "Unknown date"))
                            chat_id = convo.get("id")
                            
                            # Format timestamp for better readability
                            try:
                                datetime_obj = datetime.datetime.strptime(timestamp, "%Y-%m-%d %H:%M:%S")
                                formatted_time = datetime_obj.strftime("%m/%d %H:%M")
                            except:
                                formatted_time = timestamp
                            
                            # Get a preview of the last message for context
                            messages = convo.get("messages", [])
                            preview = ""
                            if messages:
                                last_msg = messages[-1].get("content", "")
                                preview = last_msg[:30] + "..." if len(last_msg) > 30 else last_msg
                            
                            # Display the timestamp and preview on the same line (no nested columns)
                            st.write(f"**{formatted_time}** - _{preview}_")
                            
                            if st.button(f"Load Chat", key=f"convo_{model}_{idx}"):
                                # Load this conversation
                                st.session_state.messages = convo.get("messages", [])
                                st.session_state.current_model = model
                                st.session_state.chat_id = chat_id  # Store the chat ID for future updates
                                st.success(f"Loaded chat from {formatted_time}")
                                st.rerun()
                            
                            if idx < len(sorted_convos) - 1:
                                st.markdown("---")
            else:
                st.write("No previous conversations found")
                
            # Footer info with Google AI Studio style
            st.markdown("---")
            st.markdown("AI Chat Studio | 2024")

# Run the app
# Clean up function for voice commands when the app exits
def cleanup_on_exit():
    """Clean up resources when the app exits"""
    # Stop voice processor if running
    if hasattr(st.session_state, 'voice_processor') and st.session_state.voice_processor:
        try:
            st.session_state.voice_processor.stop_listening()
            print("Stopped voice command processor")
        except:
            pass
    
    # Clean up any temporary audio files
    if hasattr(st.session_state, 'audio_path') and st.session_state.audio_path:
        try:
            from utils.audio import cleanup_audio_file
            cleanup_audio_file(st.session_state.audio_path)
        except:
            pass

if __name__ == "__main__":
    try:
        main()
    finally:
        # Execute cleanup when the app exits
        cleanup_on_exit()
